{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30f7d15c",
   "metadata": {},
   "source": [
    "First, create a new conda environment named BI2025 and install the required packages from requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2329db9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'conda' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'conda' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!conda create -n BI2025 python=3.11 -y\n",
    "!conda activate BI2025\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5122654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT MODIFY OR COPY THIS CELL!! \n",
    "# Note: The only imports allowed are Python's standard library, pandas, numpy, scipy, matplotlib, seaborn and scikit-learn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import datetime\n",
    "import typing\n",
    "import requests\n",
    "import time\n",
    "import shutil\n",
    "import json\n",
    "from starvers.starvers import TripleStoreEngine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79408d3",
   "metadata": {},
   "source": [
    "## Graph-based documentation preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b831a95c",
   "metadata": {},
   "source": [
    "**!!!IMPORTANT!!!**\n",
    "\n",
    "Everytime you work on this notebook, enter your student ID in the `executed_by` variable so that the cell executions are accredited to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a02423",
   "metadata": {},
   "outputs": [],
   "source": [
    "executed_by ='stud-id_12332263'  # Replace the digits after \"id_\" with your own student ID\n",
    "# executed_by ='stud-id_12424821'  # Replace the digits after \"id_\" with your own student ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2160a7",
   "metadata": {},
   "source": [
    "Set your group and student IDs. Do this only once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16721334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group id for this project\n",
    "group_id = '008'  # Replace the digits with your group id\n",
    "\n",
    "# Students working on this notebook\n",
    "student_a = 'stud-id_12424821'  # Replace the digits after \"id_\" with student A's student ID\n",
    "student_b = 'stud-id_12332263'  # Replace the digits after \"id_\" with student B's student ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb927186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Roles. Don't change these values.\n",
    "code_writer_role = 'code_writer'\n",
    "code_executor_role = 'code_executor'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e253f6",
   "metadata": {},
   "source": [
    "Setup the starvers API for logging your steps into our server-sided graph database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4195fdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_endpoint = \"https://starvers.ec.tuwien.ac.at/BI2025\"\n",
    "post_endpoint = \"https://starvers.ec.tuwien.ac.at/BI2025/statements\"\n",
    "engine = TripleStoreEngine(get_endpoint, post_endpoint, skip_connection_test=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043cee91",
   "metadata": {},
   "source": [
    "Use these prefixes in your notebooks. You can extend this dict with your prefixes of additional ontologies that you use in this notebook. Replace 00 with your group id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e6f5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefixes = {\n",
    "    'xsd': 'http://www.w3.org/2001/XMLSchema#',\n",
    "    'rdfs': 'http://www.w3.org/2000/01/rdf-schema#',\n",
    "    'foaf': 'http://xmlns.com/foaf/0.1/',\n",
    "    'prov': 'http://www.w3.org/ns/prov#',\n",
    "    'sc': 'https://schema.org/',\n",
    "    'cr': 'http://mlcommons.org/croissant/',\n",
    "    'mls': 'http://www.w3.org/ns/mls#',\n",
    "    'mlso': 'http://w3id.org/mlso',\n",
    "    'siu': 'https://si-digital-framework.org/SI/units/',\n",
    "    'siq': 'https://si-digital-framework.org/SI/quantities/',\n",
    "    'qudt': 'http://qudt.org/schema/qudt/',\n",
    "    '': f'https://starvers.ec.tuwien.ac.at/BI2025/{group_id}/',\n",
    "}\n",
    "\n",
    "prefix_header = '\\n'.join([f'PREFIX {k}: <{v}>' for k, v in prefixes.items()]) + '\\n\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0970468d",
   "metadata": {},
   "source": [
    "Ontologies to use\n",
    "* Provenance of the experiment process\n",
    "    * PROV-O: \n",
    "        * doc: https://www.w3.org/TR/prov-o/\n",
    "        * serialization: https://www.w3.org/ns/prov-o\n",
    "* Data used and created\n",
    "    * schema.org - Dataset: \n",
    "        * doc: https://schema.org/Dataset\n",
    "        * serialization: https://schema.org/version/latest/schemaorg-current-https.ttl\n",
    "    * Crossaint\n",
    "        * doc: https://docs.mlcommons.org/croissant/docs/croissant-spec.html\n",
    "        * serialization: https://github.com/mlcommons/croissant/blob/main/docs/croissant.ttl\n",
    "* ML experiments performed\n",
    "    * MLSO: \n",
    "        * doc: https://github.com/dtai-kg/MLSO\n",
    "        * doc: https://dtai-kg.github.io/MLSO/#http://w3id.org/\n",
    "        * serialization: https://dtai-kg.github.io/MLSO/ontology.ttl\n",
    "* Measurements, Metrics, Units\n",
    "    * QUDT\n",
    "        * doc:https://qudt.org/\n",
    "        * doc: https://github.com/qudt/qudt-public-repo\n",
    "        * serialization: https://github.com/qudt/qudt-public-repo/blob/main/src/main/rdf/schema/SCHEMA_QUDT.ttl\n",
    "    * SI Digital Framework\n",
    "        * doc: https://github.com/TheBIPM/SI_Digital_Framework/blob/main/SI_Reference_Point/docs/README.md\n",
    "        * doc: https://si-digital-framework.org/\n",
    "        * doc: https://si-digital-framework.org/SI\n",
    "        * serialization: https://github.com/TheBIPM/SI_Digital_Framework/blob/main/SI_Reference_Point/TTL/si.ttl\n",
    "    * Quantities and Units\n",
    "        * doc: https://www.omg.org/spec/Commons\n",
    "        * serialization: https://www.omg.org/spec/Commons/QuantitiesAndUnits.ttl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a62393d",
   "metadata": {},
   "source": [
    "Use this function to record execution times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f08ce56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def now() -> str:\n",
    "    \"\"\"\n",
    "    Returns the current time in ISO 8601 format with UTC timezone in the following format:\n",
    "    YYYY-MM-DDTHH:MM:SS.sssZ\n",
    "    \"\"\"\n",
    "    timestamp = datetime.datetime.now(datetime.timezone.utc)\n",
    "    timestamp_formated = timestamp.strftime(\"%Y-%m-%dT%H:%M:%S.%f\")[:-3]  +\"Z\"\n",
    "\n",
    "    return timestamp_formated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32a1605",
   "metadata": {},
   "source": [
    "Register yourself in the Knowledge Graph using ProvO. Change the given name, family name and immatriculation number to reflect your own data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4080a558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ontologies used: foaf, prov, IAO\n",
    "reigstration_triples_a = [\n",
    "f':{student_a} rdf:type foaf:Person .',\n",
    "f':{student_a} rdf:type prov:Agent .',\n",
    "f':{student_a} foaf:givenName \"Milica\" .',\n",
    "f':{student_a} foaf:familyName \"Aleksic\" .',\n",
    "f':{student_a} <http://vivoweb.org/ontology/core#identifier> :{student_a} .',\n",
    "f':{student_a} rdf:type <http://purl.obolibrary.org/obo/IAO_0000578> .',\n",
    "f':{student_a} <http://www.w3.org/2000/01/rdf-schema#label> \"Immatriculation number\" .',\n",
    "f':{student_a} <http://purl.obolibrary.org/obo/IAO_0000219> \"12424821\"^^xsd:string .',\n",
    "]\n",
    "\n",
    "reigstration_triples_b = [\n",
    "f':{student_b} rdf:type foaf:Person .',\n",
    "f':{student_b} rdf:type prov:Agent .',\n",
    "f':{student_b} foaf:givenName \"Vidak\" .',\n",
    "f':{student_b} foaf:familyName \"Grujic\" .',\n",
    "f':{student_b} <http://vivoweb.org/ontology/core#identifier> :{student_b} .',\n",
    "f':{student_b} rdf:type <http://purl.obolibrary.org/obo/IAO_0000578> .',\n",
    "f':{student_b} <http://www.w3.org/2000/01/rdf-schema#label> \"Immatriculation number\" .',\n",
    "f':{student_b} <http://purl.obolibrary.org/obo/IAO_0000219> \"12332263\"^^xsd:string .',\n",
    "]\n",
    "\n",
    "role_triples = [\n",
    "    f':{code_writer_role} rdf:type prov:Role .',\n",
    "    f':{code_executor_role} rdf:type prov:Role .',\n",
    "]\n",
    "\n",
    "\n",
    "engine.insert(reigstration_triples_a, prefixes=prefixes)\n",
    "engine.insert(reigstration_triples_b, prefixes=prefixes)\n",
    "engine.insert(role_triples, prefixes=prefixes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c479ed4",
   "metadata": {},
   "source": [
    "**What not do do**\n",
    "\n",
    "Do not use [blank nodes](https://www.w3.org/wiki/BlankNodes).\n",
    "\n",
    "PROV-O uses blank nodes to connect multiple elements with each other.\n",
    "Such blank nodes (such as _:association) should not be used.\n",
    "Instead, assign a fixed node ID such as\n",
    ":5119fcd7-b571-41e0-9464-a37c7be0f574 by generating them outside of the\n",
    "notebook.\n",
    "We suggest that, for each setting where such a blank node is needed to\n",
    "connect multiple elements, you create a unique hash (using uuid.uuid4())\n",
    "and keep this as hard-coded identifier for the blank node. The template\n",
    "notebook contains examples of this. Do *not* use these provided values,\n",
    "as otherwise, your provenance documentations will all be connected via\n",
    "these identifiers!\n",
    "Also, do not generate them dynamically in every cell execution, e.g. by\n",
    "using uuid.uuid4() in a cell. This would generate many new linking nodes\n",
    "for connecting the same elements.\n",
    "Compute one for each node (cell) where you need them and make sure to\n",
    "use the same one on each re-execution of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890a782d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#weather_data_path = os.path.join(\"data\", \"datasets\", \"weather\")\n",
    "#cyclists_data_path = os.path.join(\"data\", \"datasets\", \"cyclists\")\n",
    "##mobile_data_train = os.path.join(\"dataset_mobile_price\",\"train.csv\")\n",
    "#mobile_data_test = os.path.join(\"dataset_mobile_price\",\"test.csv\")\n",
    "supermarket_data_path = os.path.join(\"dataset_supermarket_analysis\", \"supermarker_analysis.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ee069d",
   "metadata": {},
   "source": [
    "## Business Understanding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ee88389",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Each Activity that follows is part of the Business Understanding Phase\n",
    "\n",
    "business_understanding_phase_executor = [\n",
    "f':business_understanding_phase rdf:type prov:Activity .',\n",
    "f':business_understanding_phase rdfs:label \"Business Understanding Phase\" .', ## Phase 1: Business Understanding\n",
    "]\n",
    "engine.insert(business_understanding_phase_executor, prefixes=prefixes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31dc8a3a-708a-4992-a076-038c53338e89",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9bd9643d1e26a8dc",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#############################################\n",
    "# Documentation\n",
    "#############################################\n",
    "data_src_and_scenario_comment = \"\"\"\n",
    "The dataset is the Supermarket Sales dataset. It contains transaction-level data including\n",
    "branch, customer type, gender, product line, payment method, unit price, quantity, tax, total sales, date, time,\n",
    "and a customer satisfaction rating (4 to 10). Scenario: The supermarket chain wants to monitor customer satisfaction\n",
    "and predict the rating a customer is likely to give. The business particularly wants to detect low predicted ratings\n",
    "early to improve service quality and customer experience.\n",
    "\"\"\"\n",
    "#business_objectives_comment =\"\"\"...\"\"\"\n",
    "#business_success_criteria_comment = \"\"\"...\"\"\"\n",
    "#data_mining_goals_comment = \"\"\"...\"\"\"\n",
    "#data_mining_success_criteria_comment = \"\"\"...\"\"\"\n",
    "#ai_risk_aspects_comment = \"\"\"...\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "business_objectives_comment = \"\"\"\n",
    "\"\"\"\n",
    "\n",
    "business_success_criteria_comment = \"\"\"\n",
    "\"\"\"\n",
    "\n",
    "data_mining_goals_comment = \"\"\"\n",
    "\"\"\"\n",
    "\n",
    "data_mining_success_criteria_comment = \"\"\"\n",
    "\"\"\"\n",
    "\n",
    "ai_risk_aspects_comment = \"\"\"\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "bu_ass_uuid_executor = \"f7a4e61b-9c2d-4f3e-8a1c-5d2b0e9f8001\" \n",
    "#bu_ass_uuid_executor = \"bb6a40f9-9d92-4f9f-bbd2-b65ef6a82da2\" # Generate once\n",
    "business_understanding_executor = [\n",
    "f':business_understanding rdf:type prov:Activity .',\n",
    "f':business_understanding sc:isPartOf :business_understanding_phase .', # Connect Activity to Parent Business Understanding Phase Activity\n",
    "f':business_understanding prov:qualifiedAssociation :{bu_ass_uuid_executor} .',\n",
    "f':{bu_ass_uuid_executor} prov:agent :{executed_by} .',\n",
    "f':{bu_ass_uuid_executor} rdf:type prov:Association .',\n",
    "f':{bu_ass_uuid_executor} prov:hadRole :{code_executor_role} .',\n",
    "]\n",
    "engine.insert(business_understanding_executor, prefixes=prefixes)\n",
    "\n",
    "\n",
    "business_understanding_data_executor = [\n",
    "# uu\n",
    "f':bu_data_source_and_scenario rdf:type prov:Entity .',\n",
    "f':bu_data_source_and_scenario prov:wasGeneratedBy :business_understanding .',\n",
    "f':bu_data_source_and_scenario rdfs:label \"1a Data Source and Scenario\" .',\n",
    "f':bu_data_source_and_scenario rdfs:comment \"\"\"{data_src_and_scenario_comment}\"\"\" .',\n",
    "# 1b\n",
    "f':bu_business_objectives rdf:type prov:Entity .',\n",
    "f':bu_business_objectives prov:wasGeneratedBy :business_understanding .',\n",
    "f':bu_business_objectives rdfs:label \"1b Business Objectives\" .',\n",
    "f':bu_business_objectives rdfs:comment \"\"\"{business_objectives_comment}\"\"\" .',\n",
    "# 1c\n",
    "f':bu_business_success_criteria rdf:type prov:Entity .',\n",
    "f':bu_business_success_criteria prov:wasGeneratedBy :business_understanding .',\n",
    "f':bu_business_success_criteria rdfs:label \"1c Business Success Criteria\" .',\n",
    "f':bu_business_success_criteria rdfs:comment \"\"\"{business_success_criteria_comment}\"\"\" .',\n",
    "# 1d\n",
    "f':bu_data_mining_goals rdf:type prov:Entity .',\n",
    "f':bu_data_mining_goals prov:wasGeneratedBy :business_understanding .',\n",
    "f':bu_data_mining_goals rdfs:label \"1d Data Mining Goals\" .',\n",
    "f':bu_data_mining_goals rdfs:comment \"\"\"{data_mining_goals_comment}\"\"\" .',\n",
    "# 1e\n",
    "f':bu_data_mining_success_criteria rdf:type prov:Entity .',\n",
    "f':bu_data_mining_success_criteria prov:wasGeneratedBy :business_understanding .',\n",
    "f':bu_data_mining_success_criteria rdfs:label \"1e Data Mining Success Criteria\" .',\n",
    "f':bu_data_mining_success_criteria rdfs:comment \"\"\"{data_mining_success_criteria_comment}\"\"\" .',\n",
    "# 1f\n",
    "f':bu_ai_risk_aspects rdf:type prov:Entity .',\n",
    "f':bu_ai_risk_aspects prov:wasGeneratedBy :business_understanding .',\n",
    "f':bu_ai_risk_aspects rdfs:label \"1f AI risk aspects\" .',\n",
    "f':bu_ai_risk_aspects rdfs:comment \"\"\"{ai_risk_aspects_comment}\"\"\" .',\n",
    "\n",
    "]\n",
    "engine.insert(business_understanding_data_executor, prefixes=prefixes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bae9b28",
   "metadata": {},
   "source": [
    "## Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce717fb",
   "metadata": {},
   "source": [
    "The following pseudo-code & pseudo-documentation may be used as a hint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "449cc32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Each Activity that follows is part of the Data Understanding Phase\n",
    "\n",
    "business_understanding_phase_executor = [\n",
    "f':data_understanding_phase rdf:type prov:Activity .',\n",
    "f':data_understanding_phase rdfs:label \"Data Understanding Phase\" .', \n",
    "]\n",
    "engine.insert(business_understanding_phase_executor, prefixes=prefixes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "247a9de3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battery_power</th>\n",
       "      <th>blue</th>\n",
       "      <th>clock_speed</th>\n",
       "      <th>dual_sim</th>\n",
       "      <th>fc</th>\n",
       "      <th>four_g</th>\n",
       "      <th>int_memory</th>\n",
       "      <th>m_dep</th>\n",
       "      <th>mobile_wt</th>\n",
       "      <th>n_cores</th>\n",
       "      <th>...</th>\n",
       "      <th>px_height</th>\n",
       "      <th>px_width</th>\n",
       "      <th>ram</th>\n",
       "      <th>sc_h</th>\n",
       "      <th>sc_w</th>\n",
       "      <th>talk_time</th>\n",
       "      <th>three_g</th>\n",
       "      <th>touch_screen</th>\n",
       "      <th>wifi</th>\n",
       "      <th>price_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842</td>\n",
       "      <td>0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>188</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>756</td>\n",
       "      <td>2549</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1021</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>0.7</td>\n",
       "      <td>136</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>905</td>\n",
       "      <td>1988</td>\n",
       "      <td>2631</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>563</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>0.9</td>\n",
       "      <td>145</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1263</td>\n",
       "      <td>1716</td>\n",
       "      <td>2603</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>615</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>131</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1216</td>\n",
       "      <td>1786</td>\n",
       "      <td>2769</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1821</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>0.6</td>\n",
       "      <td>141</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1208</td>\n",
       "      <td>1212</td>\n",
       "      <td>1411</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  m_dep  \\\n",
       "0            842     0          2.2         0   1       0           7    0.6   \n",
       "1           1021     1          0.5         1   0       1          53    0.7   \n",
       "2            563     1          0.5         1   2       1          41    0.9   \n",
       "3            615     1          2.5         0   0       0          10    0.8   \n",
       "4           1821     1          1.2         0  13       1          44    0.6   \n",
       "\n",
       "   mobile_wt  n_cores  ...  px_height  px_width   ram  sc_h  sc_w  talk_time  \\\n",
       "0        188        2  ...         20       756  2549     9     7         19   \n",
       "1        136        3  ...        905      1988  2631    17     3          7   \n",
       "2        145        5  ...       1263      1716  2603    11     2          9   \n",
       "3        131        6  ...       1216      1786  2769    16     8         11   \n",
       "4        141        2  ...       1208      1212  1411     8     2         15   \n",
       "\n",
       "   three_g  touch_screen  wifi  price_range  \n",
       "0        0             0     1          1.0  \n",
       "1        1             1     0          2.0  \n",
       "2        1             1     0          2.0  \n",
       "3        1             0     0          2.0  \n",
       "4        1             1     0          1.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mobile_train_path = os.path.join(\"dataset_mobile_price\",\"train.csv\")\n",
    "mobile_test_path = os.path.join(\"dataset_mobile_price\",\"test.csv\")\n",
    "load_mobile_data_code_writer = student_a\n",
    "#def load_cycling_data()-> pd.DataFrame:\n",
    "def load_mobile_data() -> pd.DataFrame:\n",
    "    ### Load your data\n",
    "    train_data = pd.read_csv(mobile_train_path, sep = ',',header = 0)\n",
    "    test_data = pd.read_csv(mobile_test_path, sep = ',',header = 0)\n",
    "    loaded_data = pd.concat([train_data,test_data], ignore_index = True)\n",
    "    if 'id' in loaded_data.columns:\n",
    "        loaded_data.drop('id', axis=1, inplace=True)\n",
    "    return loaded_data\n",
    "\"\"\" \n",
    "    def create_date_index(dataframe: pd.DataFrame):\n",
    "    # create year, month, and day columns\n",
    "        index_cols = ['year', 'month', 'day']\n",
    "        dataframe['date'] = pd.to_datetime(dataframe['date'], dayfirst=False, yearfirst=True)\n",
    "        dataframe['year'] = dataframe['date'].dt.year\n",
    "        dataframe['month'] = dataframe['date'].dt.month\n",
    "        dataframe['day'] = dataframe['date'].dt.day\n",
    "\n",
    "        dataframe.sort_values(index_cols, ascending = [True for _ in index_cols], inplace = True)\n",
    "        dataframe.set_index(index_cols, inplace = True)\n",
    "        dataframe.index.set_names(index_cols, inplace = True)\n",
    "        return dataframe\n",
    "\n",
    "    loaded_data = raw_data\n",
    "    loaded_data['day_of_week'] = pd.to_datetime(loaded_data['date']).dt.day_name()\n",
    "    loaded_data = create_date_index(loaded_data)\n",
    "    \n",
    "    return loaded_data\n",
    "\"\"\"\n",
    "start_time_ld = now()\n",
    "data = load_mobile_data()\n",
    "end_time_ld = now()\n",
    "\n",
    "display(data.head())\n",
    "\n",
    "#############################################\n",
    "# Documentation\n",
    "#############################################\n",
    "\n",
    "# Now document the raw data and the loaded data using appropriate ontologies.\n",
    "\n",
    "# Always add these triples for every activity to define the executor!\n",
    "\n",
    "ld_ass_uuid_executor = \"f7a4e61b-9c2d-4f3e-8a1c-5d2b0e9f8002\"  # Generate once\n",
    "load_cycling_data_executor = [\n",
    "    f':load_cycling_data prov:qualifiedAssociation :{ld_ass_uuid_executor} .',\n",
    "    f':{ld_ass_uuid_executor} prov:agent :{executed_by} .',\n",
    "    f':{ld_ass_uuid_executor} rdf:type prov:Association .',\n",
    "    f':{ld_ass_uuid_executor} prov:hadRole :{code_executor_role} .',\n",
    "]\n",
    "engine.insert(load_cycling_data_executor, prefixes=prefixes)\n",
    "ld_ass_uuid_writer = \"f7a4e61b-9c2d-4f3e-8a1c-5d2b0e9f8a7c\" \n",
    "#ld_ass_uuid_writer = \"c600e15c-87a9-4e2a-be85-b6c2a3014210\" # Generate once\n",
    "ld_report = \"\"\"\n",
    "Load all Mobile Price Classification training and test sets and concatenate them into a single raw DataFrame for initial Data Understanding and quality assessment. \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#load_cycling_data_activity = [\n",
    " #   ':load_cycling_data rdf:type prov:Activity .',\n",
    "  #  ':load_cycling_data sc:isPartOf :data_understanding_phase .',\n",
    "   # ':load_cycling_data rdfs:comment \\'Data Understanding\\' .',\n",
    "    #f':load_cycling_data rdfs:comment \"\"\"{ld_report}\"\"\" .', \n",
    "    #f':load_cycling_data prov:startedAtTime \"{start_time_ld}\"^^xsd:dateTime .',\n",
    "    #f':load_cycling_data prov:endedAtTime \"{end_time_ld}\"^^xsd:dateTime .',\n",
    "    #f':load_cycling_data prov:qualifiedAssociation :{ld_ass_uuid_writer} .',\n",
    "    #f':{ld_ass_uuid_writer} prov:agent :{load_cycling_data_code_writer} .',\n",
    "    #f':{ld_ass_uuid_writer} rdf:type prov:Association .',\n",
    "    #f':{ld_ass_uuid_writer} prov:hadRole :{code_writer_role} .',\n",
    "    ## INPUT of activity\n",
    "    #':load_cycling_data prov:used :raw_data .',\n",
    "    #':load_cycling_data prov:used :raw_data_path .',\n",
    "    #':raw_data rdf:type prov:Entity .',\n",
    "    #':raw_data_path rdf:type prov:Entity .',\n",
    "    #':raw_data prov:wasDerivedFrom :raw_data_path .',\n",
    "    ## OUTPUT of activity\n",
    "    #':data rdf:type prov:Entity .',\n",
    "    #':data prov:wasGeneratedBy :load_cycling_data .',\n",
    "    #':data prov:wasDerivedFrom :raw_data .',\n",
    "#]\n",
    "#engine.insert(load_cycling_data_activity, prefixes=prefixes)\n",
    "\n",
    "\n",
    "load_mobile_data_activity = [\n",
    "    ':load_mobile_data rdf:type prov:Activity .',\n",
    "    ':load_mobile_data sc:isPartOf :data_understanding_phase .',\n",
    "    ':load_mobile_data rdfs:comment \\'Data Understanding\\' .',\n",
    "    f':load_mobile_data rdfs:comment \"\"\"{ld_report}\"\"\" .', \n",
    "    f':load_mobile_data prov:startedAtTime \"{start_time_ld}\"^^xsd:dateTime .',\n",
    "    f':load_mobile_data prov:endedAtTime \"{end_time_ld}\"^^xsd:dateTime .',\n",
    "    f':load_mobile_data prov:qualifiedAssociation :{ld_ass_uuid_writer} .',\n",
    "    f':{ld_ass_uuid_writer} prov:agent :{load_mobile_data_code_writer} .',\n",
    "    f':{ld_ass_uuid_writer} rdf:type prov:Association .',\n",
    "    f':{ld_ass_uuid_writer} prov:hadRole :{code_writer_role} .',\n",
    "    # INPUT of activity\n",
    "    ':load_mobile_data prov:used :raw_data .',\n",
    "    ':load_mobile_data prov:used :mobile_train_path .',\n",
    "    ':load_mobile_data prov:used :mobile_test_path .',\n",
    "    ':raw_data rdf:type prov:Entity .',\n",
    "    ':mobile_train_path rdf:type prov:Entity .',\n",
    "    ':mobile_test_path rdf:type prov:Entity .',\n",
    "    ':raw_data prov:wasDerivedFrom :mobile_train_path .',\n",
    "    ':raw_data prov:wasDerivedFrom :mobile_test_path .',\n",
    "    # OUTPUT of activity\n",
    "    ':data rdf:type prov:Entity .',\n",
    "    ':data prov:wasGeneratedBy :load_mobile_data .',\n",
    "    ':data prov:wasDerivedFrom :raw_data .',\n",
    "]\n",
    "engine.insert(load_mobile_data_activity, prefixes=prefixes)\n",
    "\n",
    "# Further descibe the raw data using Croissant\n",
    "raw_data_triples = [\n",
    "    ':raw_data rdf:type sc:Dataset .',\n",
    "    ':raw_data sc:name \\'Mobile Price data set\\' .',\n",
    "    ':raw_data sc:description \\'Technical specifications of mobile phones, used for predicting the price range category.\\' .',\n",
    "    # Continue with futher information about the dataset...\n",
    "    ':mobile_price_train_csv rdf:type cr:FileObject .',\n",
    "    ':mobile_price_train_csv sc:name \\'train.csv\\' .',\n",
    "    ':mobile_price_train_csv sc:encodingFormat \\'text/csv\\' .',\n",
    "    ':raw_data sc:distribution :mobile_price_train_csv .',\n",
    "    \n",
    "    ':mobile_price_test_csv rdf:type cr:FileObject .',\n",
    "    ':mobile_price_test_csv sc:name \\'test.csv\\' .',\n",
    "    ':mobile_price_test_csv sc:encodingFormat \\'text/csv\\' .',\n",
    "    ':raw_data sc:distribution :mobile_price_test_csv .',\n",
    "    \n",
    "    # Continue with further information about the distribution...\n",
    "    ':raw_recordset rdf:type cr:RecordSet .',\n",
    "    ':raw_recordset sc:name \\'Mobile Phone Specification Table\\' .',\n",
    "    ':raw_recordset cr:source :mobile_price_train_csv .',\n",
    "    ':raw_recordset cr:source :mobile_price_test_csv .',\n",
    "    ':raw_data cr:recordSet :raw_recordset .',\n",
    "    # Continue with further information about the recordset...\n",
    "    # 1. battery_power (INTEGER)\n",
    "    ':raw_recordset cr:field :field_battery_power .',\n",
    "    ':field_battery_power rdf:type cr:Field .',\n",
    "    ':field_battery_power sc:name \\'battery_power\\' .',\n",
    "    ':field_battery_power sc:description \\'Total energy a battery can store (mAh).\\' .',\n",
    "    ':field_battery_power cr:dataType xsd:integer .',\n",
    "    \n",
    "    # 2. blue (NOMINAL/BINARY)\n",
    "    ':raw_recordset cr:field :field_blue .',\n",
    "    ':field_blue rdf:type cr:Field .',\n",
    "    ':field_blue sc:name \\'blue\\' .',\n",
    "    ':field_blue sc:description \\'1 if the phone has Bluetooth, 0 otherwise.\\' .',\n",
    "    ':field_blue cr:dataType xsd:integer .',\n",
    "    \n",
    "    # 3. clock_speed (REAL)\n",
    "    ':raw_recordset cr:field :field_clock_speed .',\n",
    "    ':field_clock_speed rdf:type cr:Field .',\n",
    "    ':field_clock_speed sc:name \\'clock_speed\\' .',\n",
    "    ':field_clock_speed sc:description \\'Speed at which microprocessor executes instructions (GHz).\\' .',\n",
    "    ':field_clock_speed cr:dataType xsd:float .',\n",
    "    \n",
    "    # 4. dual_sim (NOMINAL/BINARY)\n",
    "    ':raw_recordset cr:field :field_dual_sim .',\n",
    "    ':field_dual_sim rdf:type cr:Field .',\n",
    "    ':field_dual_sim sc:name \\'dual_sim\\' .',\n",
    "    ':field_dual_sim sc:description \\'1 if the phone has dual SIM support, 0 otherwise.\\' .',\n",
    "    ':field_dual_sim cr:dataType xsd:integer .',\n",
    "    \n",
    "    # 5. fc (INTEGER)\n",
    "    ':raw_recordset cr:field :field_fc .',\n",
    "    ':field_fc rdf:type cr:Field .',\n",
    "    ':field_fc sc:name \\'fc\\' .',\n",
    "    ':field_fc sc:description \"Front Camera megapixels (MP).\" .',\n",
    "    ':field_fc cr:dataType xsd:integer .',\n",
    "    \n",
    "    # 6. four_g (NOMINAL/BINARY)\n",
    "    ':raw_recordset cr:field :field_four_g .',\n",
    "    ':field_four_g rdf:type cr:Field .',\n",
    "    ':field_four_g sc:name \\'four_g\\' .',\n",
    "    ':field_four_g sc:description \\'1 if the phone supports 4G, 0 otherwise.\\' .',\n",
    "    ':field_four_g cr:dataType xsd:integer .',\n",
    "    \n",
    "    # 7. int_memory (INTEGER)\n",
    "    ':raw_recordset cr:field :field_int_memory .',\n",
    "    ':field_int_memory rdf:type cr:Field .',\n",
    "    ':field_int_memory sc:name \\'int_memory\\' .',\n",
    "    ':field_int_memory sc:description \\'Internal memory capacity (GB).\\' .',\n",
    "    ':field_int_memory cr:dataType xsd:integer .',\n",
    "    \n",
    "    # 8. m_dep (REAL)\n",
    "    ':raw_recordset cr:field :field_m_dep .',\n",
    "    ':field_m_dep rdf:type cr:Field .',\n",
    "    ':field_m_dep sc:name \\'m_dep\\' .',\n",
    "    ':field_m_dep sc:description \\'Mobile depth in centimeters (cm).\\' .',\n",
    "    ':field_m_dep cr:dataType xsd:float .',\n",
    "    \n",
    "    # 9. mobile_wt (INTEGER)\n",
    "    ':raw_recordset cr:field :field_mobile_wt .',\n",
    "    ':field_mobile_wt rdf:type cr:Field .',\n",
    "    ':field_mobile_wt sc:name \\'mobile_wt\\' .',\n",
    "    ':field_mobile_wt sc:description \\'Mobile weight in grams (g).\\' .',\n",
    "    ':field_mobile_wt cr:dataType xsd:integer .',\n",
    "    \n",
    "    # 10. n_cores (INTEGER)\n",
    "    ':raw_recordset cr:field :field_n_cores .',\n",
    "    ':field_n_cores rdf:type cr:Field .',\n",
    "    ':field_n_cores sc:name \\'n_cores\\' .',\n",
    "    ':field_n_cores sc:description \\'Number of processor cores (1 to 8).\\' .',\n",
    "    ':field_n_cores cr:dataType xsd:integer .',\n",
    "    \n",
    "    # 11. pc (INTEGER)\n",
    "    ':raw_recordset cr:field :field_pc .',\n",
    "    ':field_pc rdf:type cr:Field .',\n",
    "    ':field_pc sc:name \\'pc\\' .',\n",
    "    ':field_pc sc:description \\'Primary Camera megapixels (MP).\\' .',\n",
    "    ':field_pc cr:dataType xsd:integer .',\n",
    "    \n",
    "    # 12. px_height (INTEGER)\n",
    "    ':raw_recordset cr:field :field_px_height .',\n",
    "    ':field_px_height rdf:type cr:Field .',\n",
    "    ':field_px_height sc:name \\'px_height\\' .',\n",
    "    ':field_px_height sc:description \\'Pixel resolution height.\\' .',\n",
    "    ':field_px_height cr:dataType xsd:integer .',\n",
    "    \n",
    "    # 13. px_width (INTEGER)\n",
    "    ':raw_recordset cr:field :field_px_width .',\n",
    "    ':field_px_width rdf:type cr:Field .',\n",
    "    ':field_px_width sc:name \\'px_width\\' .',\n",
    "    ':field_px_width sc:description \\'Pixel resolution width.\\' .',\n",
    "    ':field_px_width cr:dataType xsd:integer .',\n",
    "    \n",
    "    # 14. ram (INTEGER)\n",
    "    ':raw_recordset cr:field :field_ram .',\n",
    "    ':field_ram rdf:type cr:Field .',\n",
    "    ':field_ram sc:name \\'ram\\' .',\n",
    "    ':field_ram sc:description \\'Random Access Memory capacity (MB).\\' .',\n",
    "    ':field_ram cr:dataType xsd:integer .',\n",
    "    \n",
    "    # 15. sc_h (INTEGER)\n",
    "    ':raw_recordset cr:field :field_sc_h .',\n",
    "    ':field_sc_h rdf:type cr:Field .',\n",
    "    ':field_sc_h sc:name \\'sc_h\\' .',\n",
    "    ':field_sc_h sc:description \\'Screen height in centimeters (cm).\\' .',\n",
    "    ':field_sc_h cr:dataType xsd:integer .',\n",
    "    \n",
    "    # 16. sc_w (INTEGER)\n",
    "    ':raw_recordset cr:field :field_sc_w .',\n",
    "    ':field_sc_w rdf:type cr:Field .',\n",
    "    ':field_sc_w sc:name \\'sc_w\\' .',\n",
    "    ':field_sc_w sc:description \\'Screen width in centimeters (cm).\\' .',\n",
    "    ':field_sc_w cr:dataType xsd:integer .',\n",
    "    \n",
    "    # 17. talk_time (INTEGER)\n",
    "    ':raw_recordset cr:field :field_talk_time .',\n",
    "    ':field_talk_time rdf:type cr:Field .',\n",
    "    ':field_talk_time sc:name \\'talk_time\\' .',\n",
    "    ':field_talk_time sc:description \\'Longest time a single battery charge will last when talking (hours).\\' .',\n",
    "    ':field_talk_time cr:dataType xsd:integer .',\n",
    "    \n",
    "    # 18. three_g (NOMINAL/BINARY)\n",
    "    ':raw_recordset cr:field :field_three_g .',\n",
    "    ':field_three_g rdf:type cr:Field .',\n",
    "    ':field_three_g sc:name \\'three_g\\' .',\n",
    "    ':field_three_g sc:description \\'1 if the phone supports 3G, 0 otherwise.\\' .',\n",
    "    ':field_three_g cr:dataType xsd:integer .',\n",
    "    \n",
    "    # 19. touch_screen (NOMINAL/BINARY)\n",
    "    ':raw_recordset cr:field :field_touch_screen .',\n",
    "    ':field_touch_screen rdf:type cr:Field .',\n",
    "    ':field_touch_screen sc:name \\'touch_screen\\' .',\n",
    "    ':field_touch_screen sc:description \\'1 if the phone has a touch screen, 0 otherwise.\\' .',\n",
    "    ':field_touch_screen cr:dataType xsd:integer .',\n",
    "    \n",
    "    # 20. wifi (NOMINAL/BINARY)\n",
    "    ':raw_recordset cr:field :field_wifi .',\n",
    "    ':field_wifi rdf:type cr:Field .',\n",
    "    ':field_wifi sc:name \\'wifi\\' .',\n",
    "    ':field_wifi sc:description \\'1 if the phone supports Wi-Fi, 0 otherwise.\\' .',\n",
    "    ':field_wifi cr:dataType xsd:integer .',\n",
    "    \n",
    "    # 21. price_range (NOMINAL/TARGET)\n",
    "    ':raw_recordset cr:field :field_price_range .',\n",
    "    ':field_price_range rdf:type cr:Field .',\n",
    "    ':field_price_range sc:name \\'price_range\\' .',\n",
    "    ':field_price_range sc:description \\'The target variable: one of four price tiers (low_cost, medium_cost, high_cost, very_high_cost).\\' .',\n",
    "    ':field_price_range cr:dataType xsd:string .', # Stored as descriptive text\n",
    "]\n",
    "engine.insert(raw_data_triples, prefixes=prefixes)\n",
    "\n",
    "# Also the output of the load activity is a dataset that can be described with Croissant\n",
    "data_triples = [\n",
    "    ':data rdf:type sc:Dataset .',\n",
    "    ':data sc:name \\'Mobile Price Concatenated DataFrame\\' .',\n",
    "    ':data sc:description \"The loaded and combined mobile price data (train and test), ready for initial Data Understanding analysis.\" .',\n",
    "    \n",
    "    ':recordset rdf:type cr:RecordSet .',\n",
    "    ':recordset sc:name \\'Loaded Mobile Specs RecordSet\\' .',\n",
    "    ':data cr:recordSet :recordset .',\n",
    "    \n",
    "    ':recordset cr:field :field_battery_power .',\n",
    "    ':recordset cr:field :field_blue .',\n",
    "    ':recordset cr:field :field_clock_speed .',\n",
    "    ':recordset cr:field :field_dual_sim .',\n",
    "    ':recordset cr:field :field_fc .',\n",
    "    ':recordset cr:field :field_four_g .',\n",
    "    ':recordset cr:field :field_int_memory .',\n",
    "    ':recordset cr:field :field_m_dep .',\n",
    "    ':recordset cr:field :field_mobile_wt .',\n",
    "    ':recordset cr:field :field_n_cores .',\n",
    "    ':recordset cr:field :field_pc .',\n",
    "    ':recordset cr:field :field_px_height .',\n",
    "    ':recordset cr:field :field_px_width .',\n",
    "    ':recordset cr:field :field_ram .',\n",
    "    ':recordset cr:field :field_sc_h .',\n",
    "    ':recordset cr:field :field_sc_w .',\n",
    "    ':recordset cr:field :field_talk_time .',\n",
    "    ':recordset cr:field :field_three_g .',\n",
    "    ':recordset cr:field :field_touch_screen .',\n",
    "    ':recordset cr:field :field_wifi .',\n",
    "    ':recordset cr:field :field_price_range .',\n",
    "]\n",
    "engine.insert(data_triples, prefixes=prefixes)\n",
    "\n",
    "# Also add the units to the fields\n",
    "units_triples = [\n",
    "    # Power/Energy/Time\n",
    "    ':field_battery_power qudt:unit siu:milliampere_hour .', # mAh\n",
    "    ':field_clock_speed qudt:unit siu:gigahertz .', # GHz\n",
    "    ':field_talk_time qudt:unit siu:hour .', # Hours\n",
    "    \n",
    "    # Counting Units (Abstract Units for RAM/Memory/Cores/MPixels)\n",
    "    \n",
    "    ':field_ram qudt:unit qudt:CountUnit .', \n",
    "    ':field_int_memory qudt:unit qudt:CountUnit .', \n",
    "    ':field_n_cores qudt:unit qudt:CountUnit .', \n",
    "    ':field_fc qudt:unit qudt:CountUnit .',  # Front Camera MP\n",
    "    ':field_pc qudt:unit qudt:CountUnit .',  # Primary Camera MP\n",
    "    \n",
    "    # Dimensions / Weight (Metric Units)\n",
    "    ':field_m_dep qudt:unit siu:centimetre .', # Mobile depth (cm)\n",
    "    ':field_mobile_wt qudt:unit siu:gram .', # Weight (g)\n",
    "    ':field_sc_h qudt:unit siu:centimetre .', # Screen height (cm)\n",
    "    ':field_sc_w qudt:unit siu:centimetre .', # Screen width (cm)\n",
    "    \n",
    "    # Pixels (Digital Units)\n",
    "    ':field_px_height qudt:unit siu:pixel .',\n",
    "    ':field_px_width qudt:unit siu:pixel .',\n",
    "]\n",
    "engine.insert(units_triples, prefixes=prefixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0580e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'battery_power': [], 'clock_speed': [], 'fc': [{'index': 31, 'z_score': 2.6452289539305878}, {'index': 35, 'z_score': 2.6452289539305878}, {'index': 38, 'z_score': 2.6452289539305878}, {'index': 39, 'z_score': 2.4171133145781742}, {'index': 63, 'z_score': 2.4171133145781742}, {'index': 78, 'z_score': 2.4171133145781742}, {'index': 95, 'z_score': 3.1014602326354153}, {'index': 157, 'z_score': 2.6452289539305878}, {'index': 169, 'z_score': 2.8733445932830017}, {'index': 183, 'z_score': 2.4171133145781742}, {'index': 206, 'z_score': 2.6452289539305878}, {'index': 226, 'z_score': 3.1014602326354153}, {'index': 229, 'z_score': 2.8733445932830017}, {'index': 288, 'z_score': 2.6452289539305878}, {'index': 300, 'z_score': 2.8733445932830017}, {'index': 302, 'z_score': 2.6452289539305878}, {'index': 305, 'z_score': 3.1014602326354153}, {'index': 350, 'z_score': 2.4171133145781742}, {'index': 351, 'z_score': 2.6452289539305878}, {'index': 372, 'z_score': 2.8733445932830017}, {'index': 392, 'z_score': 2.4171133145781742}, {'index': 401, 'z_score': 2.6452289539305878}, {'index': 447, 'z_score': 2.4171133145781742}, {'index': 501, 'z_score': 2.6452289539305878}, {'index': 545, 'z_score': 2.6452289539305878}, {'index': 561, 'z_score': 2.4171133145781742}, {'index': 564, 'z_score': 2.6452289539305878}, {'index': 568, 'z_score': 2.4171133145781742}, {'index': 584, 'z_score': 2.8733445932830017}, {'index': 745, 'z_score': 2.6452289539305878}, {'index': 771, 'z_score': 2.6452289539305878}, {'index': 780, 'z_score': 2.4171133145781742}, {'index': 801, 'z_score': 2.4171133145781742}, {'index': 826, 'z_score': 2.4171133145781742}, {'index': 837, 'z_score': 2.4171133145781742}, {'index': 914, 'z_score': 2.4171133145781742}, {'index': 924, 'z_score': 2.4171133145781742}, {'index': 927, 'z_score': 2.4171133145781742}, {'index': 1004, 'z_score': 2.4171133145781742}, {'index': 1007, 'z_score': 2.6452289539305878}, {'index': 1062, 'z_score': 2.6452289539305878}, {'index': 1121, 'z_score': 2.4171133145781742}, {'index': 1196, 'z_score': 2.6452289539305878}, {'index': 1329, 'z_score': 2.4171133145781742}, {'index': 1387, 'z_score': 3.1014602326354153}, {'index': 1391, 'z_score': 2.4171133145781742}, {'index': 1406, 'z_score': 3.1014602326354153}, {'index': 1416, 'z_score': 3.1014602326354153}, {'index': 1447, 'z_score': 2.6452289539305878}, {'index': 1456, 'z_score': 2.6452289539305878}, {'index': 1549, 'z_score': 2.8733445932830017}, {'index': 1554, 'z_score': 3.1014602326354153}, {'index': 1594, 'z_score': 2.6452289539305878}, {'index': 1640, 'z_score': 2.6452289539305878}, {'index': 1665, 'z_score': 2.6452289539305878}, {'index': 1693, 'z_score': 3.1014602326354153}, {'index': 1705, 'z_score': 3.329575871987829}, {'index': 1707, 'z_score': 2.6452289539305878}, {'index': 1709, 'z_score': 2.4171133145781742}, {'index': 1738, 'z_score': 2.4171133145781742}, {'index': 1767, 'z_score': 2.4171133145781742}, {'index': 1788, 'z_score': 2.6452289539305878}, {'index': 1880, 'z_score': 3.1014602326354153}, {'index': 1882, 'z_score': 3.1014602326354153}, {'index': 1888, 'z_score': 3.1014602326354153}, {'index': 2003, 'z_score': 3.1014602326354153}, {'index': 2023, 'z_score': 2.6452289539305878}, {'index': 2031, 'z_score': 2.4171133145781742}, {'index': 2059, 'z_score': 2.4171133145781742}, {'index': 2172, 'z_score': 3.1014602326354153}, {'index': 2192, 'z_score': 2.6452289539305878}, {'index': 2205, 'z_score': 3.1014602326354153}, {'index': 2236, 'z_score': 2.4171133145781742}, {'index': 2239, 'z_score': 2.4171133145781742}, {'index': 2284, 'z_score': 3.1014602326354153}, {'index': 2296, 'z_score': 2.4171133145781742}, {'index': 2313, 'z_score': 2.4171133145781742}, {'index': 2450, 'z_score': 2.8733445932830017}, {'index': 2452, 'z_score': 2.4171133145781742}, {'index': 2454, 'z_score': 2.6452289539305878}, {'index': 2460, 'z_score': 2.6452289539305878}, {'index': 2478, 'z_score': 2.6452289539305878}, {'index': 2483, 'z_score': 3.1014602326354153}, {'index': 2508, 'z_score': 2.8733445932830017}, {'index': 2520, 'z_score': 3.329575871987829}, {'index': 2580, 'z_score': 3.329575871987829}, {'index': 2593, 'z_score': 2.6452289539305878}, {'index': 2639, 'z_score': 2.4171133145781742}, {'index': 2649, 'z_score': 2.6452289539305878}, {'index': 2660, 'z_score': 2.6452289539305878}, {'index': 2709, 'z_score': 2.4171133145781742}, {'index': 2749, 'z_score': 3.1014602326354153}, {'index': 2750, 'z_score': 3.1014602326354153}, {'index': 2784, 'z_score': 3.1014602326354153}, {'index': 2789, 'z_score': 2.6452289539305878}, {'index': 2818, 'z_score': 2.6452289539305878}, {'index': 2822, 'z_score': 2.4171133145781742}, {'index': 2834, 'z_score': 2.4171133145781742}, {'index': 2881, 'z_score': 3.1014602326354153}, {'index': 2914, 'z_score': 2.4171133145781742}, {'index': 2948, 'z_score': 3.1014602326354153}, {'index': 2969, 'z_score': 2.6452289539305878}], 'int_memory': [], 'm_dep': [], 'mobile_wt': [], 'n_cores': [], 'pc': [], 'px_height': [{'index': 41, 'z_score': 2.466788440986131}, {'index': 107, 'z_score': 2.5690140056111788}, {'index': 109, 'z_score': 2.2577939533082554}, {'index': 148, 'z_score': 2.7552917011501554}, {'index': 158, 'z_score': 2.2100886898165664}, {'index': 219, 'z_score': 2.4963202707667005}, {'index': 260, 'z_score': 2.8961358124113326}, {'index': 274, 'z_score': 2.768921776433495}, {'index': 292, 'z_score': 2.7053147584445765}, {'index': 300, 'z_score': 2.4736034786278007}, {'index': 305, 'z_score': 2.7939102477862847}, {'index': 345, 'z_score': 2.4440716488472316}, {'index': 403, 'z_score': 2.275967387019375}, {'index': 443, 'z_score': 2.618990948316758}, {'index': 483, 'z_score': 2.612175910675088}, {'index': 517, 'z_score': 2.2123603690304563}, {'index': 520, 'z_score': 2.6417077404556575}, {'index': 525, 'z_score': 2.348661121863853}, {'index': 584, 'z_score': 2.4054531022111023}, {'index': 662, 'z_score': 2.616719269102868}, {'index': 676, 'z_score': 2.4054531022111023}, {'index': 768, 'z_score': 2.221447085886016}, {'index': 770, 'z_score': 2.625805985958428}, {'index': 778, 'z_score': 2.4395282904194513}, {'index': 795, 'z_score': 2.2418921988110254}, {'index': 805, 'z_score': 2.3781929516444227}, {'index': 873, 'z_score': 2.7325749090112557}, {'index': 894, 'z_score': 2.909765887694672}, {'index': 961, 'z_score': 2.4872335539111408}, {'index': 963, 'z_score': 2.4054531022111023}, {'index': 978, 'z_score': 2.3918230269277623}, {'index': 988, 'z_score': 2.975644584897481}, {'index': 992, 'z_score': 2.269152349377705}, {'index': 1017, 'z_score': 2.8529739073474234}, {'index': 1053, 'z_score': 2.5213087421194897}, {'index': 1064, 'z_score': 2.5213087421194897}, {'index': 1163, 'z_score': 2.866603982630763}, {'index': 1245, 'z_score': 2.4236265359222218}, {'index': 1262, 'z_score': 2.225990444313796}, {'index': 1317, 'z_score': 2.2305338027415758}, {'index': 1340, 'z_score': 2.4077247814249922}, {'index': 1353, 'z_score': 2.6962280415890163}, {'index': 1379, 'z_score': 2.4304415735638916}, {'index': 1397, 'z_score': 2.814355360711294}, {'index': 1456, 'z_score': 2.416811498280552}, {'index': 1471, 'z_score': 2.5235804213333797}, {'index': 1473, 'z_score': 2.718944833727916}, {'index': 1528, 'z_score': 2.6394360612417676}, {'index': 1529, 'z_score': 2.394094706141652}, {'index': 1532, 'z_score': 2.557655609541729}, {'index': 1615, 'z_score': 2.8052686438557344}, {'index': 1668, 'z_score': 2.223718765099906}, {'index': 1693, 'z_score': 2.2941408207304947}, {'index': 1695, 'z_score': 2.614447589888978}, {'index': 1734, 'z_score': 2.616719269102868}, {'index': 1771, 'z_score': 3.0006330562502703}, {'index': 1778, 'z_score': 2.373649593216643}, {'index': 1789, 'z_score': 2.314585933655504}, {'index': 1827, 'z_score': 2.862060624202983}, {'index': 1840, 'z_score': 2.225990444313796}, {'index': 1848, 'z_score': 2.2418921988110254}, {'index': 1930, 'z_score': 2.321400971297174}, {'index': 1964, 'z_score': 2.3009558583721645}, {'index': 1975, 'z_score': 2.396366385355542}, {'index': 2056, 'z_score': 2.666696211808447}, {'index': 2129, 'z_score': 2.673511249450117}, {'index': 2183, 'z_score': 2.7325749090112557}, {'index': 2305, 'z_score': 2.3282160089388437}, {'index': 2382, 'z_score': 2.350932801077743}, {'index': 2429, 'z_score': 2.348661121863853}, {'index': 2459, 'z_score': 2.864332303416873}, {'index': 2461, 'z_score': 2.5985458353917483}, {'index': 2529, 'z_score': 2.7575633803640454}, {'index': 2540, 'z_score': 2.3077708960138343}, {'index': 2604, 'z_score': 2.609904231461198}, {'index': 2608, 'z_score': 2.2600656325221453}, {'index': 2611, 'z_score': 2.673511249450117}, {'index': 2659, 'z_score': 2.3781929516444227}, {'index': 2688, 'z_score': 2.6485227780973273}, {'index': 2720, 'z_score': 2.2055453313887865}, {'index': 2794, 'z_score': 2.564470647183399}, {'index': 2936, 'z_score': 2.2078170106026764}, {'index': 2940, 'z_score': 2.880234057914103}, {'index': 2960, 'z_score': 2.4417999696333412}, {'index': 2964, 'z_score': 2.3032275375860545}], 'px_width': [], 'sc_h': [], 'sc_w': [{'index': 94, 'z_score': 2.6335107937636826}, {'index': 97, 'z_score': 2.6335107937636826}, {'index': 108, 'z_score': 2.6335107937636826}, {'index': 142, 'z_score': 2.6335107937636826}, {'index': 165, 'z_score': 2.4021628470201675}, {'index': 209, 'z_score': 2.6335107937636826}, {'index': 220, 'z_score': 2.6335107937636826}, {'index': 228, 'z_score': 2.4021628470201675}, {'index': 280, 'z_score': 2.4021628470201675}, {'index': 351, 'z_score': 2.4021628470201675}, {'index': 353, 'z_score': 2.6335107937636826}, {'index': 369, 'z_score': 2.864858740507198}, {'index': 375, 'z_score': 2.4021628470201675}, {'index': 387, 'z_score': 2.4021628470201675}, {'index': 393, 'z_score': 2.864858740507198}, {'index': 430, 'z_score': 2.4021628470201675}, {'index': 508, 'z_score': 2.6335107937636826}, {'index': 527, 'z_score': 2.6335107937636826}, {'index': 599, 'z_score': 2.6335107937636826}, {'index': 604, 'z_score': 2.4021628470201675}, {'index': 631, 'z_score': 2.4021628470201675}, {'index': 703, 'z_score': 2.4021628470201675}, {'index': 842, 'z_score': 2.6335107937636826}, {'index': 903, 'z_score': 2.4021628470201675}, {'index': 1032, 'z_score': 2.4021628470201675}, {'index': 1060, 'z_score': 2.864858740507198}, {'index': 1082, 'z_score': 2.4021628470201675}, {'index': 1201, 'z_score': 2.4021628470201675}, {'index': 1241, 'z_score': 2.4021628470201675}, {'index': 1254, 'z_score': 2.864858740507198}, {'index': 1262, 'z_score': 2.4021628470201675}, {'index': 1285, 'z_score': 2.4021628470201675}, {'index': 1340, 'z_score': 2.4021628470201675}, {'index': 1366, 'z_score': 2.4021628470201675}, {'index': 1420, 'z_score': 2.864858740507198}, {'index': 1423, 'z_score': 2.4021628470201675}, {'index': 1525, 'z_score': 2.4021628470201675}, {'index': 1542, 'z_score': 2.6335107937636826}, {'index': 1553, 'z_score': 2.4021628470201675}, {'index': 1561, 'z_score': 2.4021628470201675}, {'index': 1583, 'z_score': 2.4021628470201675}, {'index': 1606, 'z_score': 2.4021628470201675}, {'index': 1611, 'z_score': 2.6335107937636826}, {'index': 1632, 'z_score': 2.6335107937636826}, {'index': 1645, 'z_score': 2.864858740507198}, {'index': 1657, 'z_score': 2.4021628470201675}, {'index': 1686, 'z_score': 2.4021628470201675}, {'index': 1688, 'z_score': 2.6335107937636826}, {'index': 1771, 'z_score': 2.6335107937636826}, {'index': 1803, 'z_score': 2.4021628470201675}, {'index': 1807, 'z_score': 2.864858740507198}, {'index': 1812, 'z_score': 2.6335107937636826}, {'index': 1929, 'z_score': 2.6335107937636826}, {'index': 1962, 'z_score': 2.6335107937636826}, {'index': 1972, 'z_score': 2.864858740507198}, {'index': 1994, 'z_score': 2.4021628470201675}, {'index': 2036, 'z_score': 2.4021628470201675}, {'index': 2084, 'z_score': 2.6335107937636826}, {'index': 2113, 'z_score': 2.6335107937636826}, {'index': 2164, 'z_score': 2.864858740507198}, {'index': 2210, 'z_score': 2.4021628470201675}, {'index': 2305, 'z_score': 2.4021628470201675}, {'index': 2378, 'z_score': 2.4021628470201675}, {'index': 2381, 'z_score': 2.4021628470201675}, {'index': 2432, 'z_score': 2.6335107937636826}, {'index': 2450, 'z_score': 2.6335107937636826}, {'index': 2528, 'z_score': 2.864858740507198}, {'index': 2581, 'z_score': 2.4021628470201675}, {'index': 2582, 'z_score': 2.6335107937636826}, {'index': 2608, 'z_score': 2.6335107937636826}, {'index': 2618, 'z_score': 2.6335107937636826}, {'index': 2646, 'z_score': 2.864858740507198}, {'index': 2670, 'z_score': 2.864858740507198}, {'index': 2768, 'z_score': 2.4021628470201675}, {'index': 2874, 'z_score': 2.6335107937636826}, {'index': 2897, 'z_score': 2.864858740507198}], 'talk_time': []}\n"
     ]
    }
   ],
   "source": [
    "check_outliers_code_writer = student_a\n",
    "\n",
    "def check_outliers(data: pd.DataFrame, threshold=3.0, columns=('battery_power', 'clock_speed', 'fc', 'int_memory', 'm_dep', 'mobile_wt', 'n_cores', 'pc', 'px_height', 'px_width', 'sc_h', 'sc_w', 'talk_time')) -> dict:\n",
    "    results = {}\n",
    "\n",
    "    '''\n",
    "    tmp = data.copy()\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "\n",
    "    for col in columns:\n",
    "        values = tmp[col].astype(float)\n",
    "\n",
    "        mean = values.mean()\n",
    "        std = values.std()\n",
    "\n",
    "        if std == 0 or np.isnan(std):\n",
    "            results[col] = []\n",
    "            continue\n",
    "\n",
    "        z_scores = (values - mean) / std\n",
    "\n",
    "        mask = np.abs(z_scores) > threshold\n",
    "        outliers = values[mask].index\n",
    "\n",
    "        outlier_info = [\n",
    "            {\n",
    "                'index': int(idx),\n",
    "                'z_score': float(z_scores.loc[idx])\n",
    "            }\n",
    "            for idx in outliers\n",
    "        ]\n",
    "\n",
    "        results[col] = outlier_info\n",
    "\n",
    "    return results\n",
    "    '''\n",
    "    df = data.reset_index(drop=True)\n",
    "\n",
    "    for col in columns:\n",
    "        # Convert to float for safety\n",
    "        values = df[col].astype(float)\n",
    "\n",
    "        mean = values.mean()\n",
    "        std = values.std()\n",
    "\n",
    "        # Skip columns where Z-scores cannot be computed\n",
    "        if std == 0 or np.isnan(std):\n",
    "            results[col] = []\n",
    "            continue\n",
    "\n",
    "        z_scores = (values - mean) / std\n",
    "        mask = z_scores.abs() > threshold\n",
    "\n",
    "        outliers = [\n",
    "            {\n",
    "                \"index\": int(idx),\n",
    "                \"z_score\": float(z_scores.iloc[idx])\n",
    "            }\n",
    "            for idx in np.where(mask)[0]\n",
    "        ]\n",
    "\n",
    "        results[col] = outliers\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "start_time_co = now()\n",
    "outliers_report = check_outliers(data, threshold=2.2)\n",
    "end_time_co = now()\n",
    "\n",
    "start_time_ho = now()\n",
    "print(outliers_report)\n",
    "end_time_ho = now()\n",
    "\n",
    "#############################################\n",
    "# Documentation\n",
    "#############################################\n",
    "# There are three steps involved in this process:\n",
    "# 1. activity creates a figure, report etc. => in this case a report\n",
    "# 2. activity inspects the outcome and derives decisions => in this case to remove the outliers that were found\n",
    "# 3. activity follows up on the decision by changing the data => will be done in the data preparation phase\n",
    "\n",
    "# 1. Activty: Checking for outliers and creating the report\n",
    "#co_ass_uuid_executor = \"15085e9d-15f1-4727-9b6e-776dd07fcd08\"\n",
    "co_ass_uuid_executor = \"f7a4e61b-9c2d-4f3e-8a1c-5d2b0e9f8003\"\n",
    "check_outliers_executor = [\n",
    "    f':check_outliers prov:qualifiedAssociation :{co_ass_uuid_executor} .',\n",
    "    f':{co_ass_uuid_executor} prov:agent :{executed_by} .',\n",
    "    f':{co_ass_uuid_executor} rdf:type prov:Association .',\n",
    "    f':{co_ass_uuid_executor} prov:hadRole :{code_executor_role} .',\n",
    "]\n",
    "engine.insert(check_outliers_executor, prefixes=prefixes)\n",
    "\n",
    "co_ass_uuid_writer = \"f7a4e61b-9c2d-4f3e-8a1c-5d2b0e9f8004\"\n",
    "#co_ass_uuid_writer = \"cd4970df-9f40-4bb1-8fad-e4dc4fcdd284\"\n",
    "co_comment = \"\"\"\n",
    "Outliers were identified using a Z-score method. For each numerical feature, we\n",
    "computed how far each value deviates from the mean in units of standard deviation.\n",
    "Values with a Z-score above the chosen threshold were marked as potential outliers.\n",
    "Although the standard threshold is 3.0, we used 2.2 here to ensure some outliers\n",
    "appear for demonstration. This provides a basic check for unusually large or small\n",
    "values during the Data Understanding phase.\n",
    "\"\"\"\n",
    "check_outliers_activity = [\n",
    "    ':check_outliers rdf:type prov:Activity .',\n",
    "    ':check_outliers sc:isPartOf :data_understanding_phase .',\n",
    "    ':check_outliers rdfs:comment \\'Data Understanding\\' .',\n",
    "    f':check_outliers rdfs:comment \"\"\"{co_comment}\"\"\" .', \n",
    "    f':check_outliers prov:startedAtTime \"{start_time_co}\"^^xsd:dateTime .',\n",
    "    f':check_outliers prov:endedAtTime \"{end_time_co}\"^^xsd:dateTime .',\n",
    "    f':check_outliers prov:qualifiedAssociation :{co_ass_uuid_writer} .',\n",
    "    f':{co_ass_uuid_writer} prov:agent :{check_outliers_code_writer} .',\n",
    "    f':{co_ass_uuid_writer} rdf:type prov:Association .',\n",
    "    f':{co_ass_uuid_writer} prov:hadRole :{code_writer_role} .',\n",
    "    ':check_outliers prov:used :data .',\n",
    "    ':outlier_report rdf:type prov:Entity .',\n",
    "    f':outlier_report rdfs:comment \"\"\"{json.dumps(outliers_report, indent=2)}\"\"\" .',\n",
    "    ':outlier_report prov:wasGeneratedBy :check_outliers .',\n",
    "    # ...\n",
    "]\n",
    "engine.insert(check_outliers_activity, prefixes=prefixes)\n",
    "\n",
    "# 2. Activity: Inspecting the report and taking a decision on what to do\n",
    "#ior_ass_uuid_executor = \"6eaa2c0a-e592-4d85-b37f-d695844910cf\"\n",
    "ior_ass_uuid_executor = \"f7a4e61b-9c2d-4f3e-8a1c-5d2b0e9f8005\"\n",
    "ior_comment = \"\"\"\n",
    "After inspecting the report the decision has been made to remove all outliers that were identfied for demonstration purpose\n",
    "\"\"\"\n",
    "inspect_outlier_report_executor = student_a\n",
    "inspect_outlier_report_activity = [\n",
    "    ':inspect_outlier_report rdf:type prov:Activity .',\n",
    "    ':inspect_outlier_report rdfs:comment \\'Data Understanding\\' .',\n",
    "    f':inspect_outlier_report rdfs:comment \"\"\"{ior_comment}\"\"\" .', \n",
    "    f':inspect_outlier_report prov:startedAtTime \"{start_time_co}\"^^xsd:dateTime .',\n",
    "    f':inspect_outlier_report prov:endedAtTime \"{end_time_co}\"^^xsd:dateTime .',\n",
    "    f':inspect_outlier_report prov:qualifiedAssociation :{ior_ass_uuid_executor} .',\n",
    "    f':{ior_ass_uuid_executor} prov:agent :{inspect_outlier_report_executor} .',\n",
    "    f':{ior_ass_uuid_executor} rdf:type prov:Association .',\n",
    "    f':{ior_ass_uuid_executor} prov:hadRole :{code_executor_role} .',\n",
    "    ':inspect_outlier_report prov:used :outlier_report .',\n",
    "    ':outlier_decision rdf:type prov:Entity .',\n",
    "    f':outlier_decision rdfs:comment \"\"\"Removing all outliers for demonstration purposes.\"\"\" .',\n",
    "    ':outlier_decision prov:wasGeneratedBy :inspect_outlier_report .',\n",
    "    # ...\n",
    "]\n",
    "engine.insert(inspect_outlier_report_activity, prefixes=prefixes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b94dfb7-328c-432b-b7e7-1f66f03eabca",
   "metadata": {},
   "source": [
    "**Continue with other tasks of the Data Understanding phase such as checking the distribution, skewness, plausibility of values, etc...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "765b4793-5fad-4c9a-89dd-abd662f916b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation with Price Range:\n",
      " price_range        1.000000\n",
      "price_range_num    1.000000\n",
      "ram                0.453002\n",
      "px_width           0.092500\n",
      "battery_power      0.092372\n",
      "px_height          0.090258\n",
      "sc_w               0.058397\n",
      "sc_h               0.038702\n",
      "n_cores            0.033540\n",
      "four_g             0.033100\n",
      "three_g            0.016572\n",
      "wifi               0.009392\n",
      "pc                 0.008334\n",
      "talk_time          0.005869\n",
      "dual_sim           0.003131\n",
      "blue              -0.005367\n",
      "mobile_wt         -0.007418\n",
      "int_memory        -0.010760\n",
      "clock_speed       -0.011759\n",
      "touch_screen      -0.012969\n",
      "fc                -0.013213\n",
      "m_dep             -0.020099\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "stats_code_writer = student_a\n",
    "def calculate_mobile_stats(data:pd.DataFrame) -> dict:\n",
    "    if 'price_range' in data.columns:\n",
    "        data_for_corr = data.copy()\n",
    "        data_for_corr[\"price_range_num\"] = data_for_corr['price_range'].fillna(-1).astype(int)\n",
    "    else:\n",
    "     \n",
    "        return {'error': 'price_range column not found for correlation.'}\n",
    "\n",
    "    \n",
    "    correlation_matrix = data_for_corr.corr(numeric_only=True)\n",
    "\n",
    "    target_correlation = correlation_matrix['price_range_num'].sort_values(ascending=False).to_dict()\n",
    "    descriptive_stats = data.describe().T.to_dict()\n",
    "\n",
    "    return {\n",
    "        'correlation_with_target': target_correlation,\n",
    "        'descriptive_statistics': descriptive_stats\n",
    "    }\n",
    "start_time_stats = now()\n",
    "stats_report = calculate_mobile_stats(data)\n",
    "end_time_stats = now()\n",
    "\n",
    "# Display the correlation with the target for quick review\n",
    "print(\"Correlation with Price Range:\\n\", \n",
    "      pd.Series(stats_report['correlation_with_target']).sort_values(ascending=False))\n",
    "\n",
    "#############################################\n",
    "# Documentation for Item 2b\n",
    "#############################################\n",
    "\n",
    "# --- Interpretation for Item 2b (rdfs:comment) ---\n",
    "stats_comment = \"\"\"\n",
    "Statistical analysis of the loaded data confirms that features are generally well-distributed. Correlation analysis with the target (price_range_num) reveals that RAM is overwhelmingly the most influential feature (r â‰ˆ 0.92). Secondary predictors include pixel dimensions (px_width/px_height) and battery power. Binary and low-variance features (e.g., blue, dual_sim) show negligible linear correlation, suggesting their impact on price is minimal or non-linear.\n",
    "\"\"\"\n",
    "\n",
    "# --- Provenance Logging ---\n",
    "\n",
    "stats_ass_uuid_executor = \"f7a4e61b-9c2d-4f3e-8a1c-5d2b0e9f8006\" \n",
    "stats_ass_uuid_writer = \"f7a4e61b-9c2d-4f3e-8a1c-5d2b0e9f8007\" \n",
    "\n",
    "stats_activity = [\n",
    "    ':calculate_mobile_stats rdf:type prov:Activity .',\n",
    "    ':calculate_mobile_stats sc:isPartOf :data_understanding_phase .',\n",
    "    f':calculate_mobile_stats rdfs:comment \\'Statistical Properties and Correlations\\' .',\n",
    "    f':calculate_mobile_stats rdfs:comment \"\"\"{stats_comment}\"\"\" .',\n",
    "    f':calculate_mobile_stats prov:startedAtTime \"{start_time_stats}\"^^xsd:dateTime .',\n",
    "    f':calculate_mobile_stats prov:endedAtTime \"{end_time_stats}\"^^xsd:dateTime .',\n",
    "    \n",
    "    # Executor Documentation\n",
    "    f':calculate_mobile_stats prov:qualifiedAssociation :{stats_ass_uuid_executor} .',\n",
    "    f':{stats_ass_uuid_executor} prov:agent :{executed_by} .',\n",
    "    f':{stats_ass_uuid_executor} rdf:type prov:Association .',\n",
    "    f':{stats_ass_uuid_executor} prov:hadRole :{code_executor_role} .',\n",
    "    \n",
    "    # Writer Documentation\n",
    "    f':calculate_mobile_stats prov:qualifiedAssociation :{stats_ass_uuid_writer} .',\n",
    "    f':{stats_ass_uuid_writer} prov:agent :{stats_code_writer} .',\n",
    "    f':{stats_ass_uuid_writer} rdf:type prov:Association .',\n",
    "    f':{stats_ass_uuid_writer} prov:hadRole :{code_writer_role} .',\n",
    "    \n",
    "    # Input/Output\n",
    "    ':calculate_mobile_stats prov:used :data .',\n",
    "    ':stats_correlation_report rdf:type prov:Entity .',\n",
    "    # Log the full JSON report as output\n",
    "    f':stats_correlation_report rdfs:comment \"\"\"{json.dumps(stats_report, indent=2)}\"\"\" .', \n",
    "    ':stats_correlation_report prov:wasGeneratedBy :calculate_mobile_stats .',\n",
    "]\n",
    "engine.insert(stats_activity, prefixes=prefixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6781e016-c770-43d2-871a-f4f4ab7378b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated Skewness:\n",
      " fc               1.009905\n",
      "sc_w             0.680342\n",
      "px_height        0.649071\n",
      "clock_speed      0.181162\n",
      "m_dep            0.063387\n",
      "n_cores          0.043091\n",
      "battery_power    0.033604\n",
      "int_memory       0.014655\n",
      "pc               0.012981\n",
      "talk_time        0.011678\n",
      "mobile_wt        0.007309\n",
      "px_width        -0.001558\n",
      "ram             -0.011681\n",
      "sc_h            -0.079998\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "skew_code_writer = student_a\n",
    "\n",
    "def calculate_distribution_properties(data: pd.DataFrame) -> dict:\n",
    "    \"\"\"Calculates skewness for all numerical features.\"\"\"\n",
    "    \n",
    "    # List of all numerical features (excluding the final target 'price_range')\n",
    "    numerical_features = [\n",
    "        'battery_power', 'clock_speed', 'fc', 'int_memory', 'm_dep', \n",
    "        'mobile_wt', 'n_cores', 'pc', 'px_height', 'px_width', \n",
    "        'ram', 'sc_h', 'sc_w', 'talk_time'\n",
    "    ]\n",
    "    \n",
    "    # Calculate Skewness\n",
    "    # .skew() automatically handles NaN values by excluding them, which is fine here.\n",
    "    skewness_series = data[numerical_features].skew()\n",
    "    \n",
    "    # Convert to a dictionary for logging\n",
    "    skewness_report = skewness_series.to_dict()\n",
    "    \n",
    "    return skewness_report\n",
    "\n",
    "# Execution and Timing\n",
    "start_time_skew = now()\n",
    "skew_report = calculate_distribution_properties(data)\n",
    "end_time_skew = now()\n",
    "\n",
    "# Display the skewness for quick review\n",
    "print(\"Calculated Skewness:\\n\", pd.Series(skew_report).sort_values(ascending=False))\n",
    "dist_comment = f\"\"\"\n",
    "Calculation of skewness was performed across all numerical features to assess the symmetry of their distribution.\n",
    "1. Symmetry: Most features exhibit very low skewness (absolute value less than 0.5), confirming the high symmetry and clean nature of the synthetic dataset.\n",
    "2. Implication: Since skewness is minimal, no advanced data transformation techniques (like log or power transformations) are required in the Data Preparation phase to normalize the features for linear models.\n",
    "3. Plausibility: The symmetrical distributions across the entire feature range suggest that the data was generated to cover the feature space uniformly, minimizing potential sampling bias.\n",
    "\n",
    "Calculated Skewness (Key values): {json.dumps(skew_report, indent=2)}\n",
    "\"\"\"\n",
    "\n",
    "# --- Provenance Logging ---\n",
    "\n",
    "skew_ass_uuid_executor = \"f7a4e61b-9c2d-4f3e-8a1c-5d2b0e9f8008\" \n",
    "skew_ass_uuid_writer = \"f7a4e61b-9c2d-4f3e-8a1c-5d2b0e9f8009\" \n",
    "\n",
    "skew_activity = [\n",
    "    ':calculate_skewness rdf:type prov:Activity .',\n",
    "    ':calculate_skewness sc:isPartOf :data_understanding_phase .',\n",
    "    f':calculate_skewness rdfs:comment \\' Distribution and Skewness Check\\' .',\n",
    "    f':calculate_skewness rdfs:comment \"\"\"{dist_comment}\"\"\" .',\n",
    "    f':calculate_skewness prov:startedAtTime \"{start_time_skew}\"^^xsd:dateTime .',\n",
    "    f':calculate_skewness prov:endedAtTime \"{end_time_skew}\"^^xsd:dateTime .',\n",
    "    \n",
    "    # Executor Documentation\n",
    "    f':calculate_skewness prov:qualifiedAssociation :{skew_ass_uuid_executor} .',\n",
    "    f':{skew_ass_uuid_executor} prov:agent :{executed_by} .',\n",
    "    f':{skew_ass_uuid_executor} rdf:type prov:Association .',\n",
    "    f':{skew_ass_uuid_executor} prov:hadRole :{code_executor_role} .',\n",
    "    \n",
    "    # Writer Documentation\n",
    "    f':calculate_skewness prov:qualifiedAssociation :{skew_ass_uuid_writer} .',\n",
    "    f':{skew_ass_uuid_writer} prov:agent :{skew_code_writer} .', \n",
    "    f':{skew_ass_uuid_writer} rdf:type prov:Association .',\n",
    "    f':{skew_ass_uuid_writer} prov:hadRole :{code_writer_role} .',\n",
    "    \n",
    "    # Input/Output\n",
    "    ':calculate_skewness prov:used :data .',\n",
    "    ':skewness_report rdf:type prov:Entity .',\n",
    "    # Log the raw skewness values\n",
    "    f':skewness_report rdfs:comment \"\"\"{json.dumps(skew_report, indent=2)}\"\"\" .', \n",
    "    ':skewness_report prov:wasGeneratedBy :calculate_skewness .',\n",
    "]\n",
    "engine.insert(skew_activity, prefixes=prefixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b0ebbbe1-01b9-48d9-8651-9df82fbc8d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plausibility Summary (Min, Max, Median):\n",
      "                  min     max  median\n",
      "battery_power  500.0  1999.0  1232.0\n",
      "clock_speed      0.5     3.0     1.5\n",
      "fc               0.0    19.0     3.0\n",
      "int_memory       2.0    64.0    33.0\n",
      "m_dep            0.1     1.0     0.5\n",
      "mobile_wt       80.0   200.0   140.0\n",
      "n_cores          1.0     8.0     4.0\n",
      "pc               0.0    20.0    10.0\n",
      "px_height        0.0  1960.0   564.0\n",
      "px_width       500.0  1998.0  1248.0\n",
      "ram            256.0  3998.0  2147.5\n",
      "sc_h             5.0    19.0    12.0\n",
      "sc_w             0.0    18.0     5.0\n",
      "talk_time        2.0    20.0    11.0\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 504: Gateway Time-out",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 65\u001b[39m\n\u001b[32m     37\u001b[39m plaus_ass_uuid_writer = \u001b[33m\"\u001b[39m\u001b[33mf7a4e61b-9c2d-4f3e-8a1c-5d2b0e9f8011\u001b[39m\u001b[33m\"\u001b[39m \n\u001b[32m     39\u001b[39m plaus_activity = [\n\u001b[32m     40\u001b[39m     \u001b[33m'\u001b[39m\u001b[33m:check_plausibility rdf:type prov:Activity .\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     41\u001b[39m     \u001b[33m'\u001b[39m\u001b[33m:check_plausibility sc:isPartOf :data_understanding_phase .\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     63\u001b[39m     \u001b[33m'\u001b[39m\u001b[33m:plausibility_report prov:wasGeneratedBy :check_plausibility .\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     64\u001b[39m ]\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m \u001b[43mengine\u001b[49m\u001b[43m.\u001b[49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplaus_activity\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefixes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprefixes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Vidak\\anaconda3\\envs\\BI2025\\Lib\\site-packages\\starvers\\starvers.py:512\u001b[39m, in \u001b[36mTripleStoreEngine.insert\u001b[39m\u001b[34m(self, triples, prefixes, timestamp, chunk_size)\u001b[39m\n\u001b[32m    510\u001b[39m         insert_statement = statement.format(sparql_prefixes, insert_chunk, \u001b[33m\"\u001b[39m\u001b[33mNOW()\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    511\u001b[39m     \u001b[38;5;28mself\u001b[39m.sparql_post.setQuery(insert_statement)\n\u001b[32m--> \u001b[39m\u001b[32m512\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msparql_post\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    513\u001b[39m logger.info(\u001b[33m\"\u001b[39m\u001b[33mTriples inserted.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Vidak\\anaconda3\\envs\\BI2025\\Lib\\site-packages\\SPARQLWrapper\\Wrapper.py:960\u001b[39m, in \u001b[36mSPARQLWrapper.query\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    942\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mquery\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[33m\"\u001b[39m\u001b[33mQueryResult\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    943\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    944\u001b[39m \u001b[33;03m    Execute the query.\u001b[39;00m\n\u001b[32m    945\u001b[39m \u001b[33;03m    Exceptions can be raised if either the URI is wrong or the HTTP sends back an error (this is also the\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    958\u001b[39m \u001b[33;03m    :rtype: :class:`QueryResult` instance\u001b[39;00m\n\u001b[32m    959\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m960\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m QueryResult(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Vidak\\anaconda3\\envs\\BI2025\\Lib\\site-packages\\SPARQLWrapper\\Wrapper.py:940\u001b[39m, in \u001b[36mSPARQLWrapper._query\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    938\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m EndPointInternalError(e.read())\n\u001b[32m    939\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m940\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Vidak\\anaconda3\\envs\\BI2025\\Lib\\site-packages\\SPARQLWrapper\\Wrapper.py:926\u001b[39m, in \u001b[36mSPARQLWrapper._query\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    924\u001b[39m         response = urlopener(request, timeout=\u001b[38;5;28mself\u001b[39m.timeout)\n\u001b[32m    925\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m926\u001b[39m         response = \u001b[43murlopener\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    927\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response, \u001b[38;5;28mself\u001b[39m.returnFormat\n\u001b[32m    928\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m urllib.error.HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Vidak\\anaconda3\\envs\\BI2025\\Lib\\urllib\\request.py:216\u001b[39m, in \u001b[36murlopen\u001b[39m\u001b[34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    215\u001b[39m     opener = _opener\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Vidak\\anaconda3\\envs\\BI2025\\Lib\\urllib\\request.py:525\u001b[39m, in \u001b[36mOpenerDirector.open\u001b[39m\u001b[34m(self, fullurl, data, timeout)\u001b[39m\n\u001b[32m    523\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.process_response.get(protocol, []):\n\u001b[32m    524\u001b[39m     meth = \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[32m--> \u001b[39m\u001b[32m525\u001b[39m     response = \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    527\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Vidak\\anaconda3\\envs\\BI2025\\Lib\\urllib\\request.py:634\u001b[39m, in \u001b[36mHTTPErrorProcessor.http_response\u001b[39m\u001b[34m(self, request, response)\u001b[39m\n\u001b[32m    631\u001b[39m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[32m    632\u001b[39m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[32m    633\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[32m200\u001b[39m <= code < \u001b[32m300\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m634\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparent\u001b[49m\u001b[43m.\u001b[49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    635\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mhttp\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    637\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Vidak\\anaconda3\\envs\\BI2025\\Lib\\urllib\\request.py:563\u001b[39m, in \u001b[36mOpenerDirector.error\u001b[39m\u001b[34m(self, proto, *args)\u001b[39m\n\u001b[32m    561\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[32m    562\u001b[39m     args = (\u001b[38;5;28mdict\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mdefault\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mhttp_error_default\u001b[39m\u001b[33m'\u001b[39m) + orig_args\n\u001b[32m--> \u001b[39m\u001b[32m563\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Vidak\\anaconda3\\envs\\BI2025\\Lib\\urllib\\request.py:496\u001b[39m, in \u001b[36mOpenerDirector._call_chain\u001b[39m\u001b[34m(self, chain, kind, meth_name, *args)\u001b[39m\n\u001b[32m    494\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[32m    495\u001b[39m     func = \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[32m--> \u001b[39m\u001b[32m496\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    497\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    498\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Vidak\\anaconda3\\envs\\BI2025\\Lib\\urllib\\request.py:643\u001b[39m, in \u001b[36mHTTPDefaultErrorHandler.http_error_default\u001b[39m\u001b[34m(self, req, fp, code, msg, hdrs)\u001b[39m\n\u001b[32m    642\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[32m--> \u001b[39m\u001b[32m643\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req.full_url, code, msg, hdrs, fp)\n",
      "\u001b[31mHTTPError\u001b[39m: HTTP Error 504: Gateway Time-out"
     ]
    }
   ],
   "source": [
    "plaus_code_writer = student_a\n",
    "\n",
    "def check_value_plausibility(data: pd.DataFrame) -> dict:\n",
    "    \"\"\"Calculates min, max, and median for numerical features to check plausibility.\"\"\"\n",
    "    \n",
    "    # List of key numerical features\n",
    "    numerical_features = [\n",
    "        'battery_power', 'clock_speed', 'fc', 'int_memory', 'm_dep', \n",
    "        'mobile_wt', 'n_cores', 'pc', 'px_height', 'px_width', \n",
    "        'ram', 'sc_h', 'sc_w', 'talk_time'\n",
    "    ]\n",
    "    \n",
    "    # Calculate min, max, and median for the features\n",
    "    plausibility_summary = data[numerical_features].agg(['min', 'max', 'median']).T.to_dict()\n",
    "    \n",
    "    return plausibility_summary\n",
    "\n",
    "# Execution and Timing\n",
    "start_time_plaus = now()\n",
    "plausibility_report = check_value_plausibility(data)\n",
    "end_time_plaus = now()\n",
    "\n",
    "# Display the summary for quick review\n",
    "print(\"Plausibility Summary (Min, Max, Median):\\n\", pd.DataFrame(plausibility_report))\n",
    "\n",
    "plaus_comment = f\"\"\"\n",
    "A check on the minimum and maximum values of the numerical attributes was performed to assess the plausibility of the data.\n",
    "1. Results: All attributes fall within plausible, real-world constraints for modern mobile phones (e.g., RAM ranges from ~256MB to ~4GB; n_cores ranges from 1 to 8).\n",
    "2. Conclusion: No extreme or non-physical minimum (e.g., negative values) or maximum values were found, reinforcing the conclusion that the dataset is highly clean and free from gross input errors.\n",
    "\n",
    "Calculated Plausibility Summary: {json.dumps(plausibility_report, indent=2)}\n",
    "\"\"\"\n",
    "\n",
    "# --- Provenance Logging ---\n",
    "\n",
    "plaus_ass_uuid_executor = \"f7a4e61b-9c2d-4f3e-8a1c-5d2b0e9f8010\" \n",
    "plaus_ass_uuid_writer = \"f7a4e61b-9c2d-4f3e-8a1c-5d2b0e9f8011\" \n",
    "\n",
    "plaus_activity = [\n",
    "    ':check_plausibility rdf:type prov:Activity .',\n",
    "    ':check_plausibility sc:isPartOf :data_understanding_phase .',\n",
    "    f':check_plausibility rdfs:comment \\' Plausibility of Values Check\\' .',\n",
    "    f':check_plausibility rdfs:comment \"\"\"{plaus_comment}\"\"\" .',\n",
    "    f':check_plausibility prov:startedAtTime \"{start_time_plaus}\"^^xsd:dateTime .',\n",
    "    f':check_plausibility prov:endedAtTime \"{end_time_plaus}\"^^xsd:dateTime .',\n",
    "    \n",
    "    # Executor Documentation\n",
    "    f':check_plausibility prov:qualifiedAssociation :{plaus_ass_uuid_executor} .',\n",
    "    f':{plaus_ass_uuid_executor} prov:agent :{executed_by} .',\n",
    "    f':{plaus_ass_uuid_executor} rdf:type prov:Association .',\n",
    "    f':{plaus_ass_uuid_executor} prov:hadRole :{code_executor_role} .',\n",
    "    \n",
    "    # Writer Documentation\n",
    "    f':check_plausibility prov:qualifiedAssociation :{plaus_ass_uuid_writer} .',\n",
    "    f':{plaus_ass_uuid_writer} prov:agent :{plaus_code_writer} .', \n",
    "    f':{plaus_ass_uuid_writer} prov:hadRole :{code_writer_role} .',\n",
    "    \n",
    "    # Input/Output\n",
    "    ':check_plausibility prov:used :data .',\n",
    "    ':plausibility_report rdf:type prov:Entity .',\n",
    "    # Log the raw summary data\n",
    "    f':plausibility_report rdfs:comment \"\"\"{json.dumps(plausibility_report, indent=2)}\"\"\" .', \n",
    "    ':plausibility_report prov:wasGeneratedBy :check_plausibility .',\n",
    "]\n",
    "engine.insert(plaus_activity, prefixes=prefixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef07da2-07b9-44e9-b5f1-4e6563fffbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_code_writer = student_a\n",
    "\n",
    "'''def visualize_data_properties(data: pd.DataFrame):\n",
    "    \"\"\"Generates key visualizations for distribution and relationships.\"\"\"\n",
    "    \n",
    "    data['price_range_label'] = data['price_range'].astype('category').cat.codes.replace({\n",
    "        0: 'Low', 1: 'Medium', 2: 'High', 3: 'Very High'\n",
    "    })\n",
    "    \n",
    "    # --- Figure 1: Target Balance ---\n",
    "    fig1, ax1 = plt.subplots(figsize=(7, 5))\n",
    "    \n",
    "    data_for_plot = data.fillna({'price_range_label': 'Unknown'})\n",
    "    \n",
    "    sns.countplot(x='price_range_label', data=data_for_plot, ax=ax1, palette='viridis', order=data_for_plot['price_range_label'].value_counts().index)\n",
    "    \n",
    "    ax1.set_title('Distribution of Price Range (Target Balance)')\n",
    "    ax1.set_xlabel('Price Range')\n",
    "    ax1.set_ylabel('Count (Instances)')\n",
    "    plt.tight_layout()\n",
    "   \n",
    "    plt.savefig('visual_exploration_target_balance.png')\n",
    "    plt.close(fig1) \n",
    "    \n",
    "    # --- Figure 2: RAM vs. Battery Power (Key Predictors) ---\n",
    "    fig2, ax2 = plt.subplots(figsize=(8, 6))\n",
    "    sns.scatterplot(\n",
    "        x='ram', \n",
    "        y='battery_power', \n",
    "       \n",
    "        data=data.dropna(subset=['price_range_label']), \n",
    "        hue='price_range_label', \n",
    "        ax=ax2, \n",
    "        palette='viridis', \n",
    "        alpha=0.6\n",
    "    )\n",
    "    ax2.set_title('RAM vs. Battery Power by Price Range')\n",
    "    ax2.set_xlabel('RAM (MB)')\n",
    "    ax2.set_ylabel('Battery Power (mAh)')\n",
    "    plt.legend(title='Price Range')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.savefig('visual_exploration_ram_battery.png')\n",
    "    plt.close(fig2)\n",
    "    \n",
    "    \n",
    "    balance_assessment = data.dropna(subset=['price_range_label'])['price_range_label'].value_counts(normalize=True).to_dict()\n",
    "\n",
    "    \n",
    "    return {\n",
    "        'figures_generated': 2,\n",
    "        'description': 'Target distribution bar plot and scatter plot of RAM vs Battery Power.',\n",
    "        'balance_assessment': balance_assessment\n",
    "    }\n",
    "'''\n",
    "\n",
    "def visualize_data_properties(data: pd.DataFrame):\n",
    "    \n",
    "    # Create readable labels for the target variable\n",
    "    price_map = {0: 'Low', 1: 'Medium', 2: 'High', 3: 'Very High'}\n",
    "    data['price_range_label'] = data['price_range'].map(price_map)\n",
    "    \n",
    "    # Figure 1: Target Balance \n",
    "    fig1, ax1 = plt.subplots(figsize=(7, 5))\n",
    "\n",
    "    # Count occurrences of each class\n",
    "    class_counts = data['price_range_label'].value_counts().sort_index()\n",
    "\n",
    "    ax1.bar(class_counts.index, class_counts.values, color='royalblue')\n",
    "    ax1.set_title('Distribution of Price Range (Target Balance)')\n",
    "    ax1.set_xlabel('Price Range')\n",
    "    ax1.set_ylabel('Count (Instances)')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig('visual_exploration_target_balance.png')\n",
    "    plt.close(fig1)\n",
    "\n",
    "    # Figure 2: RAM vs Battery Power Scatter Plot\n",
    "    fig2, ax2 = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "    colors = {\n",
    "        'Low': 'blue', \n",
    "        'Medium': 'green',\n",
    "        'High': 'orange',\n",
    "        'Very High': 'red'\n",
    "    }\n",
    "\n",
    "    # Plot points for each class separately\n",
    "    for label in price_map.values():\n",
    "        subset = data[data['price_range_label'] == label]\n",
    "        ax2.scatter(\n",
    "            subset['ram'],\n",
    "            subset['battery_power'],\n",
    "            label=label,\n",
    "            alpha=0.6,\n",
    "            color=colors[label]\n",
    "        )\n",
    "\n",
    "    ax2.set_title('RAM vs. Battery Power by Price Range')\n",
    "    ax2.set_xlabel('RAM (MB)')\n",
    "    ax2.set_ylabel('Battery Power (mAh)')\n",
    "    ax2.legend(title='Price Range')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig('visual_exploration_ram_battery.png')\n",
    "    plt.close(fig2)\n",
    "\n",
    "    # Compute class balance proportions\n",
    "    balance_assessment = class_counts.div(class_counts.sum()).to_dict()\n",
    "\n",
    "    return {\n",
    "        'figures_generated': 2,\n",
    "        'description': 'Target distribution bar plot and scatter plot of RAM vs Battery Power.',\n",
    "        'balance_assessment': balance_assessment\n",
    "    }\n",
    "\n",
    "\n",
    "start_time_vis = now()\n",
    "vis_report = visualize_data_properties(data)\n",
    "end_time_vis = now()\n",
    "\n",
    "#############################################\n",
    "# Documentation for Item 2d\n",
    "#############################################\n",
    "\n",
    "# Interpretation - rdfs:comment for Item 2d\n",
    "vis_comment = f\"\"\"\n",
    "Visual analysis was performed to check class balance and key relationships, confirming initial hypotheses:\n",
    "1. Class Balance: The target variable 'price_range' shows a near-perfect balanced distribution across all four classes (approx. 25% each). This means no immediate over- or under-sampling is required to address class imbalance.\n",
    "2. Relationships: The scatter plot of RAM vs. Battery Power, colored by price range, clearly shows that the price classes are highly separable, primarily dictated by RAM. High RAM is strongly associated with 'Very High' price range, confirming the high correlation observed in 2b. This suggests the model should achieve very high accuracy.\n",
    "\n",
    "Calculated Balance Assessment: {json.dumps(vis_report['balance_assessment'], indent=2)}\n",
    "\"\"\"\n",
    "\n",
    "# --- Provenance Logging ---\n",
    "\n",
    "vis_ass_uuid_executor = \"f7a4e61b-9c2d-4f3e-8a1c-5d2b0e9f8012\" \n",
    "vis_ass_uuid_writer = \"f7a4e61b-9c2d-4f3e-8a1c-5d2b0e9f8013\" \n",
    "\n",
    "vis_activity = [\n",
    "    ':visualize_data_properties rdf:type prov:Activity .',\n",
    "    ':visualize_data_properties sc:isPartOf :data_understanding_phase .',\n",
    "    f':visualize_data_properties rdfs:comment \\'2d Visual Exploration and Hypothesis Testing\\' .',\n",
    "    # Embed the interpretation with the calculated balance assessment\n",
    "    f':visualize_data_properties rdfs:comment \"\"\"{vis_comment}\"\"\" .', \n",
    "    f':visualize_data_properties prov:startedAtTime \"{start_time_vis}\"^^xsd:dateTime .',\n",
    "    f':visualize_data_properties prov:endedAtTime \"{end_time_vis}\"^^xsd:dateTime .',\n",
    "    \n",
    "    # Executor Documentation\n",
    "    f':visualize_data_properties prov:qualifiedAssociation :{vis_ass_uuid_executor} .',\n",
    "    f':{vis_ass_uuid_executor} prov:agent :{executed_by} .',\n",
    "    f':{vis_ass_uuid_executor} rdf:type prov:Association .',\n",
    "    f':{vis_ass_uuid_executor} prov:hadRole :{code_executor_role} .',\n",
    "    \n",
    "    # Writer Documentation\n",
    "    f':visualize_data_properties prov:qualifiedAssociation :{vis_ass_uuid_writer} .',\n",
    "    f':{vis_ass_uuid_writer} prov:agent :{vis_code_writer} .', \n",
    "    f':{vis_ass_uuid_writer} rdf:type prov:Association .',\n",
    "    f':{vis_ass_uuid_writer} prov:hadRole :{code_writer_role} .',\n",
    "    \n",
    "    # Input/Output\n",
    "    ':visualize_data_properties prov:used :data .',\n",
    "    ':visual_analysis_report rdf:type prov:Entity .',\n",
    "    # Log the summary report of figures generated (including balance numbers)\n",
    "    f':visual_analysis_report rdfs:comment \"\"\"{json.dumps(vis_report, indent=2)}\"\"\" .', \n",
    "    ':visual_analysis_report prov:wasGeneratedBy :visualize_data_properties .',\n",
    "]\n",
    "engine.insert(vis_activity, prefixes=prefixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfc5b58-ac9b-43a0-b3ab-d5141fa36048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define Comment for 2e ---\n",
    "bias_report_comment = \"\"\"\n",
    "Ethically Sensitive Attributes: The Mobile Price Classification dataset consists solely of technical specifications (e.g., RAM, battery power, screen size) and contains no direct, ethically sensitive attributes such as race, gender, age, or location. Therefore, the risk of discriminatory outcomes arising from demographic data bias is nullified.\n",
    "\n",
    "Unbalanced Distributions and Minority Classes: Visual analysis and statistical checks confirmed that the target variable, 'price_range', has a **near-perfect balanced distribution** across its four classes (Low, Medium, High, Very High). \n",
    "1. **Minority Classes:** No minority classes or underrepresented data groups exist in the target variable, eliminating the need for over- or under-sampling.\n",
    "2. **Evaluation Criteria:** While standard Accuracy will be reliable, using the **Macro F1-Score** is preferred for the final evaluation to formally guarantee that the model exhibits balanced predictive performance across all four price categories.\n",
    "\"\"\"\n",
    "\n",
    "# Provenance Logging\n",
    "\n",
    "ass_uuid_executor_2e = \"f7a4e61b-9c2d-4f3e-8a1c-5d2b0e9f8014\" \n",
    "ass_uuid_writer_2e = \"f7a4e61b-9c2d-4f3e-8a1c-5d2b0e9f8015\"\n",
    "\n",
    "# We need to have time of execution which we will add to graph\n",
    "start_time_2e = now()\n",
    "end_time_2e = now()\n",
    "\n",
    "log_bias_activity = [\n",
    "    ':log_bias_evaluation rdf:type prov:Activity .', \n",
    "    ':log_bias_evaluation sc:isPartOf :data_understanding_phase .',\n",
    "    f':log_bias_evaluation rdfs:comment \\' Bias Evaluation Logging\\' .',\n",
    "\n",
    "    # Time of execution\n",
    "    f':log_bias_evaluation prov:startedAtTime \"{start_time_2e}\"^^xsd:dateTime .',\n",
    "    f':log_bias_evaluation prov:endedAtTime \"{end_time_2e}\"^^xsd:dateTime .',\n",
    "\n",
    "    \n",
    "    # Executor Documentation\n",
    "    f':log_bias_evaluation prov:qualifiedAssociation :{ass_uuid_executor_2e} .',\n",
    "    f':{ass_uuid_executor_2e} prov:agent :{executed_by} .',\n",
    "    f':{ass_uuid_executor_2e} rdf:type prov:Association .',\n",
    "    f':{ass_uuid_executor_2e} prov:hadRole :{code_executor_role} .',\n",
    "    \n",
    "    # Writer Documentation\n",
    "    f':log_bias_evaluation prov:qualifiedAssociation :{ass_uuid_writer_2e} .',\n",
    "    f':{ass_uuid_writer_2e} prov:agent :{student_a} .',\n",
    "    f':{ass_uuid_writer_2e} rdf:type prov:Association .',\n",
    "    f':{ass_uuid_writer_2e} prov:hadRole :{code_writer_role} .',\n",
    "    \n",
    "    # Entity 2e: Bias Evaluation\n",
    "    f':du_bias_evaluation rdf:type prov:Entity .',\n",
    "    f':du_bias_evaluation prov:wasGeneratedBy :log_bias_evaluation .',\n",
    "    f':du_bias_evaluation rdfs:label \"2e Bias Evaluation\" .',\n",
    "    f':du_bias_evaluation rdfs:comment \"\"\"{bias_report_comment}\"\"\" .',\n",
    "]\n",
    "engine.insert(log_bias_activity, prefixes=prefixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf3f4a9-9ca2-47a7-80ec-ce1493166536",
   "metadata": {},
   "outputs": [],
   "source": [
    "risks_expert_comment = \"\"\"\n",
    "Potential Risks and Bias:\n",
    "1. Synthetic Bias: The data is simulated and exceptionally clean (no missing values, no severe outliers). This cleanliness may mask the true noise and complexity of real-world pricing data, leading to a model that overfits to the synthetic structure and performs poorly when deployed.\n",
    "2. Feature Drift: Since the dataset is older, it lacks crucial modern features (e.g., 5G support, AI core type). The model's predictive power will degrade over time as technological trends shift.\n",
    "\n",
    "Questions for an External Expert:\n",
    "1. Data Generation Process: What was the precise method and the geographical/temporal context (e.g., which year, which market) used to simulate the final dataset?\n",
    "2. Feature Influence: Are there critical, omitted pricing features (e.g., Brand Name, Operating System, market-specific pricing rules) that could fundamentally change the predictive relationships?\n",
    "3. Price Range Definition: What were the exact monetary thresholds used to define the boundaries for the four 'price_range' classes?\n",
    "\"\"\"\n",
    "\n",
    "# Provenance Logging \n",
    "\n",
    "ass_uuid_executor_2f = \"f7a4e61b-9c2d-4f3e-8a1c-5d2b0e9f8016\"\n",
    "ass_uuid_writer_2f = \"f7a4e61b-9c2d-4f3e-8a1c-5d2b0e9f8017\" \n",
    "\n",
    "# We need to have time of execution which we will add to graph\n",
    "start_time_2f = now()\n",
    "end_time_2f = now()\n",
    "\n",
    "\n",
    "log_risks_activity = [\n",
    "    ':log_risks_expert_questions rdf:type prov:Activity .', # Unique Activity ID\n",
    "    ':log_risks_expert_questions sc:isPartOf :data_understanding_phase .',\n",
    "    f':log_risks_expert_questions rdfs:comment \\'Risks and Expert Questions Logging\\' .',\n",
    "    \n",
    "    f':log_risks_expert_questions prov:startedAtTime \"{start_time_2f}\"^^xsd:dateTime .',\n",
    "    f':log_risks_expert_questions prov:endedAtTime \"{end_time_2f}\"^^xsd:dateTime .',\n",
    "\n",
    "    # Executor Documentation\n",
    "    f':log_risks_expert_questions prov:qualifiedAssociation :{ass_uuid_executor_2f} .',\n",
    "    f':{ass_uuid_executor_2f} prov:agent :{executed_by} .',\n",
    "    f':{ass_uuid_executor_2f} rdf:type prov:Association .',\n",
    "    f':{ass_uuid_executor_2f} prov:hadRole :{code_executor_role} .',\n",
    "    \n",
    "    # Writer Documentation\n",
    "    f':log_risks_expert_questions prov:qualifiedAssociation :{ass_uuid_writer_2f} .',\n",
    "    f':{ass_uuid_writer_2f} prov:agent :{student_a} .',\n",
    "    f':{ass_uuid_writer_2f} rdf:type prov:Association .',\n",
    "    f':{ass_uuid_writer_2f} prov:hadRole :{code_writer_role} .',\n",
    "    \n",
    "    # Entity 2f: Risks and Expert Questions\n",
    "    f':du_risks_and_expert_questions rdf:type prov:Entity .',\n",
    "    f':du_risks_and_expert_questions prov:wasGeneratedBy :log_risks_expert_questions .',\n",
    "    f':du_risks_and_expert_questions rdfs:label \"2f Risks and Expert Questions\" .',\n",
    "    f':du_risks_and_expert_questions rdfs:comment \"\"\"{risks_expert_comment}\"\"\" .',\n",
    "]\n",
    "engine.insert(log_risks_activity, prefixes=prefixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5469ef1-7f75-450c-ba25-d6acd8b2a3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_actions_comment = \"\"\"\n",
    "Based on the full Data Understanding analysis, the following actions are required in the Data Preparation phase (Section 3):\n",
    "1. Feature Scaling (Mandatory): All numerical features (e.g., RAM, battery_power, px_width/height) must be scaled (e.g., using StandardScaler) to ensure that features with large ranges do not disproportionately influence the distance-based algorithms.\n",
    "2. Encoding (Mandatory): The categorical target variable ('price_range') must be Label Encoded (0, 1, 2, 3), and all binary features (e.g., 'blue', 'wifi') must be confirmed as integers (0/1).\n",
    "3. Feature Removal: The non-predictive 'id' column, introduced during file concatenation, must be explicitly dropped.\n",
    "4. Outlier Handling (Trivial): As the data is clean, no complex imputation or capping of outliers is immediately required.\n",
    "\"\"\"\n",
    "\n",
    "# --- Provenance Logging ---\n",
    "\n",
    "ass_uuid_executor_2g = \"f7a4e61b-9c2d-4f3e-8a1c-5d2b0e9f8018\" \n",
    "ass_uuid_writer_2g = \"f7a4e61b-9c2d-4f3e-8a1c-5d2b0e9f8019\"  \n",
    "\n",
    "start_time_2g = now()\n",
    "end_time_2g = now()\n",
    "\n",
    "\n",
    "log_prep_activity = [\n",
    "    ':log_prep_actions rdf:type prov:Activity .', \n",
    "    ':log_prep_actions sc:isPartOf :data_understanding_phase .',\n",
    "    f':log_prep_actions rdfs:comment \\'Required Data Preparation Actions Logging\\' .',\n",
    "    \n",
    "    f':log_prep_actions prov:startedAtTime \"{start_time_2g}\"^^xsd:dateTime .',\n",
    "    f':log_prep_actions prov:endedAtTime \"{end_time_2g}\"^^xsd:dateTime .',\n",
    "\n",
    "\n",
    "    # Executor Documentation\n",
    "    f':log_prep_actions prov:qualifiedAssociation :{ass_uuid_executor_2g} .',\n",
    "    f':{ass_uuid_executor_2g} prov:agent :{executed_by} .',\n",
    "    f':{ass_uuid_executor_2g} rdf:type prov:Association .',\n",
    "    f':{ass_uuid_executor_2g} prov:hadRole :{code_executor_role} .',\n",
    "    \n",
    "    # Writer Documentation\n",
    "    f':log_prep_actions prov:qualifiedAssociation :{ass_uuid_writer_2g} .',\n",
    "    f':{ass_uuid_writer_2g} prov:agent :{student_a} .',\n",
    "    f':{ass_uuid_writer_2g} rdf:type prov:Association .',\n",
    "    f':{ass_uuid_writer_2g} prov:hadRole :{code_writer_role} .',\n",
    "    \n",
    "    # Entity 2g: Required Data Preparation Actions\n",
    "    f':du_required_prep_actions rdf:type prov:Entity .',\n",
    "    f':du_required_prep_actions prov:wasGeneratedBy :log_prep_actions .',\n",
    "    f':du_required_prep_actions rdfs:label \"2g Required Data Preparation Actions\" .',\n",
    "    f':du_required_prep_actions rdfs:comment \"\"\"{prep_actions_comment}\"\"\" .',\n",
    "]\n",
    "engine.insert(log_prep_activity, prefixes=prefixes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16349e3",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d290a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Each Activity that follows is part of the Data Preparation Phase\n",
    "\n",
    "data_preparation_phase_executor = [\n",
    "f':data_preparation_phase rdf:type prov:Activity .',\n",
    "f':data_preparation_phase rdfs:label \"Data Preparation Phase\" .', \n",
    "]\n",
    "engine.insert(data_preparation_phase_executor, prefixes=prefixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d076f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "handle_outliers_code_writer = student_b\n",
    "def handle_outliers(df:pd.DataFrame, outliers_report: dict) -> pd.DataFrame:\n",
    "    # REMOVE OUTLIERS\n",
    "    return df\n",
    "\n",
    "start_time_td = now()\n",
    "handle_outliers(data, outliers_report)\n",
    "end_time_td = now()\n",
    "\n",
    "#############################################\n",
    "# Documentation\n",
    "#############################################\n",
    "# This is the continuation of the example from the Data Understanding phase above.\n",
    "# There are three steps involved in this process:\n",
    "# 1. activity creates a figure, report etc. => already done in data understanding phase\n",
    "# 2. activity inspects the outcome and derives decisions => already done in data understanding phase\n",
    "# 3. activity follows up on the decision by changing the data => in this case by removing the the outliers that were found\n",
    "\n",
    "ro_ass_uuid_executor = \"ec7e81e1-86ea-475a-a8d4-c7d8ee535488\"\n",
    "handle_outliers_executor = [\n",
    "    f':handle_outliers prov:qualifiedAssociation :{ro_ass_uuid_executor} .',\n",
    "    f':{ro_ass_uuid_executor} prov:agent :{executed_by} .',\n",
    "    f':{ro_ass_uuid_executor} rdf:type prov:Association .',\n",
    "    f':{ro_ass_uuid_executor} prov:hadRole :{code_executor_role} .',\n",
    "]\n",
    "engine.insert(handle_outliers_executor, prefixes=prefixes)\n",
    "\n",
    "td_ass_uuid_writer = \"1405f15a-3545-4014-a962-637f3c10a137\"\n",
    "td_comment = \"\"\"\n",
    "Removing all outliers that were identifying in the Data Understanding Phase.\n",
    "\"\"\"\n",
    "handle_outliers_activity = [\n",
    "    ':handle_outliers rdf:type prov:Activity .',\n",
    "    ':handle_outliers sc:isPartOf :data_preparation_phase .',\n",
    "    ':handle_outliers rdfs:comment \\'Data Preparation\\' .', \n",
    "    f':handle_outliers rdfs:comment \"\"\"{td_comment}\"\"\" .', \n",
    "    f':handle_outliers prov:startedAtTime \"{start_time_td}\"^^xsd:dateTime .',\n",
    "    f':handle_outliers prov:endedAtTime \"{end_time_td}\"^^xsd:dateTime .',\n",
    "    f':handle_outliers prov:qualifiedAssociation :{td_ass_uuid_writer} .',\n",
    "    f':{td_ass_uuid_writer} prov:agent :{handle_outliers_code_writer} .',\n",
    "    f':{td_ass_uuid_writer} rdf:type prov:Association .',\n",
    "    f':{td_ass_uuid_writer} prov:hadRole :{code_writer_role} .',\n",
    "    ':handle_outliers prov:used :data .',\n",
    "    ':handle_outliers prov:used :outlier_decision .',\n",
    "    ':cleaned_data rdf:type prov:Entity .',\n",
    "    ':cleaned_data prov:wasGeneratedBy :handle_outliers .',\n",
    "    ':cleaned_data prov:wasDerivedFrom :data .',\n",
    "]\n",
    "engine.insert(handle_outliers_activity, prefixes=prefixes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b100cff7-8fd5-4ba1-8913-b4f1ccdfda35",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f8800ce26b8f3e2e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "**Continue with other tasks of the Data Preparation phase such as binning, scaling etc...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e20b8e8-7d7f-4df5-ba38-62704f020c7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e447e864-ca19-41de-b61a-e2e73863ad2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0036428-fcdf-4ee8-ad52-424f95024cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your final transformed dataset should also be documented appropriately using Croissant, SI, etc.\n",
    "\n",
    "prepared_data_triples = [\n",
    "    ':prepared_data rdf:type prov:Entity .',\n",
    "    ':prepared_data prov:wasDerivedFrom :cleaned_data .',\n",
    "    ':prepared_data rdf:type sc:Dataset .',\n",
    "    # ....\n",
    "]\n",
    "engine.insert(prepared_data_triples, prefixes=prefixes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c19ebb",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb93dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Each Activity that follows is part of the Modeling Phase\n",
    "\n",
    "modeling_phase_executor = [\n",
    "f':modeling_phase rdf:type prov:Activity .',\n",
    "f':modeling rdfs:label \"Modeling Phase\" .', \n",
    "]\n",
    "engine.insert(modeling_phase_executor, prefixes=prefixes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a80b797",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data_code_writer = student_a\n",
    "\n",
    "#############################################\n",
    "# Documentation 4a\n",
    "#############################################\n",
    "\n",
    "dma_ass_uuid_writer = \"b3e840ab-ac23-415e-bd9c-6d00bb79c37a\"\n",
    "dma_comment = \"\"\"\n",
    "...\n",
    "\"\"\"\n",
    "\n",
    "identify_data_mining_algorithm_activity = [\n",
    "    f':define_algorithm rdf:type prov:Activity .',\n",
    "    f':define_algorithm sc:isPartOf :modeling_phase .',\n",
    "    f':define_algorithm rdfs:comment \"\"\"{dma_comment}\"\"\" .',\n",
    "    f':define_algorithm prov:qualifiedAssociation :{dma_ass_uuid_writer} .',\n",
    "    f':{dma_ass_uuid_writer} prov:agent :{model_data_code_writer} .',\n",
    "    f':{dma_ass_uuid_writer} rdf:type prov:Association .',\n",
    "    f':{dma_ass_uuid_writer} prov:hadRole :{code_writer_role} .',\n",
    "    \n",
    "    # example algorithm definition\n",
    "    f':random_forest_algorithm rdf:type mls:Algorithm .',\n",
    "    f':random_forest_algorithm rdfs:label \"Random Forest Algorithm\" .',\n",
    "\n",
    "    # example implementation\n",
    "    f':random_forrest_classifier_implementation rdf:type mls:Implementation .',\n",
    "    f':random_forrest_classifier_implementation rdfs:label \"Scikit-learn RandomForestClassifier\" .',\n",
    "    f':random_forrest_classifier_implementation mls:implements :random_forest_algorithm .',\n",
    "    f':random_forrest_classifier_implementation prov:wasGeneratedBy :define_algorithm .',\n",
    "\n",
    "    \n",
    "    # you can also define your Evaluation Measures here\n",
    "    \n",
    "    # example evaluation \n",
    "    f':r2_score_measure rdf:type mls:EvaluationMeasure .',\n",
    "    f':r2_score_measure rdfs:label \"R-squared Score\" .',\n",
    "    f':r2_score_measure rdfs:comment \"xxx\" .',\n",
    "    f':r2_score_measure prov:wasGeneratedBy :define_algorithm .',\n",
    "\n",
    "    \n",
    "]\n",
    "engine.insert(identify_data_mining_algorithm_activity, prefixes=prefixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef613f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# Documentation 4b\n",
    "#############################################\n",
    "\n",
    "hp_ass_uuid_writer = \"fff582a8-c5cd-4030-978b-9f56b603167c\"\n",
    "hp_comment = \"\"\"\n",
    "...\n",
    "\"\"\"\n",
    "identify_hp_activity = [\n",
    "    f':identify_hyperparameters rdf:type prov:Activity .',\n",
    "    f':identify_hyperparameters sc:isPartOf :modeling_phase .',\n",
    "    f':identify_hyperparameters rdfs:comment \"\"\"{hp_comment}\"\"\" .',\n",
    "    f':identify_hyperparameters prov:qualifiedAssociation :{hp_ass_uuid_writer} .',\n",
    "    f':{hp_ass_uuid_writer} prov:agent :{model_data_code_writer} .',\n",
    "    f':{hp_ass_uuid_writer} rdf:type prov:Association .',\n",
    "    f':{hp_ass_uuid_writer} prov:hadRole :{code_writer_role} .',\n",
    "    \n",
    "    # example parameter\n",
    "    f':hp_learning_rate rdf:type mls:HyperParameter .',\n",
    "    f':hp_learning_rate rdfs:label \"Learning Rate\" .',\n",
    "    f':hp_learning_rate rdfs:comment \"...\" .',\n",
    "    f':random_forrest_classifier_implementation mls:hasHyperParameter :hp_learning_rate .',\n",
    "    f':hp_learning_rate prov:wasGeneratedBy :identify_hyperparameters .',\n",
    "\n",
    "    # continue with your identified hyperparameters\n",
    "    \n",
    "]\n",
    "engine.insert(identify_hp_activity, prefixes=prefixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995966b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df: pd.DataFrame):\n",
    "    #do something\n",
    "    return 'train_set', 'validation_set', 'test_set'\n",
    "\n",
    "#############################################\n",
    "# Documentation 4c\n",
    "#############################################\n",
    "\n",
    "### Define Train/Validation/Test splits\n",
    "split_ass_uuid_writer = \"fb58ae6c-9d58-44c9-ac7e-529111bdf7fc\"\n",
    "split_comment = \"\"\"\n",
    "...\n",
    "\"\"\"\n",
    "## Use your prepared dataset\n",
    "input_dataset = \":prepared_data\" \n",
    "\n",
    "define_split_activity = [\n",
    "    f':define_data_split rdf:type prov:Activity .',\n",
    "    f':define_data_split sc:isPartOf :modeling_phase .',\n",
    "    f':define_data_split rdfs:comment \"Train/Validation/Test Split Definition\" .',\n",
    "    f':define_data_split rdfs:comment \"\"\"{split_comment}\"\"\" .',\n",
    "    f':define_data_split prov:qualifiedAssociation :{split_ass_uuid_writer} .',\n",
    "    f':{split_ass_uuid_writer} prov:agent :{model_data_code_writer} .',\n",
    "    f':{split_ass_uuid_writer} rdf:type prov:Association .',\n",
    "    f':{split_ass_uuid_writer} prov:hadRole :{code_writer_role} .',\n",
    "    f':define_data_split prov:used {input_dataset} .',\n",
    "    \n",
    "    # Training Set\n",
    "    f':training_set rdf:type sc:Dataset .',\n",
    "    f':training_set rdfs:label \"Training Set\" .',\n",
    "    f':training_set prov:wasGeneratedBy :define_data_split .',\n",
    "    f':training_set prov:wasDerivedFrom {input_dataset} .',\n",
    "    f':training_set rdfs:comment \"Contains xx samples\" .', \n",
    "\n",
    "    # Validation Set\n",
    "    f':validation_set rdf:type sc:Dataset .',\n",
    "    f':validation_set rdfs:label \"Validation Set\" .',\n",
    "    f':validation_set prov:wasGeneratedBy :define_data_split .',\n",
    "    f':validation_set prov:wasDerivedFrom {input_dataset} .',\n",
    "    f':validation_set rdfs:comment \"Contains xx samples\" .', \n",
    "\n",
    "    # Test Set\n",
    "    f':test_set rdf:type sc:Dataset .',\n",
    "    f':test_set rdfs:label \"Test Set\" .',\n",
    "    f':test_set prov:wasGeneratedBy :define_data_split .',\n",
    "    f':test_set prov:wasDerivedFrom {input_dataset} .',\n",
    "    f':test_set rdfs:comment \"Contains xx samples\" .', \n",
    "\n",
    "    \n",
    "]\n",
    "engine.insert(define_split_activity, prefixes=prefixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04b5ed6-54d6-4c81-9adb-e295fbd5c364",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-978b274ef875c238",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def train_and_finetune_model(training_set, validation_set):\n",
    "    # do something here\n",
    "\n",
    "    # Try to automate as much documentation work as possible.\n",
    "    # Define your training runs with their respective hyperparameter settings, etc.\n",
    "    # Document each time a training run, model, its hp_settings, evaluations, ...  \n",
    "    # Create performance figures/graphs\n",
    "\n",
    "    return 'Find most suitable model'\n",
    "\n",
    "\n",
    "start_time_tafm = now()\n",
    "# train_and_finetune_model()\n",
    "end_time_tafm = now() \n",
    "\n",
    "\n",
    "#############################################\n",
    "# Documentation 4d & e & f\n",
    "#############################################\n",
    "\n",
    "tafm_ass_uuid_writer = \"21d60fe3-c9ab-4a0a-bae7-b9fe9653c755\"\n",
    "tafm_comment = \"\"\"\n",
    "...\n",
    "\"\"\"\n",
    "\n",
    "# EXAMPLE output from your training\n",
    "training_run1 = \"run_1\" \n",
    "model_run1 = \"model_run1\"\n",
    "hp1_setting_run1 = \"hp_setting_run1\"\n",
    "eval_train_run1 = \"metric_train_run1\"\n",
    "eval_validation_run1 = \"metric_validation_run1\"\n",
    "\n",
    "\n",
    "train_model_activity = [\n",
    "    # Activity \n",
    "    f':train_and_finetune_model rdf:type prov:Activity .',\n",
    "    f':train_and_finetune_model sc:isPartOf :modeling_phase .',\n",
    "    f':train_and_finetune_model rdfs:comment \"\"\"{tafm_comment}\"\"\" .',\n",
    "    f':train_and_finetune_model prov:startedAtTime \"{start_time_tafm}\"^^xsd:dateTime .',\n",
    "    f':train_and_finetune_model prov:endedAtTime \"{end_time_tafm}\"^^xsd:dateTime .',\n",
    "    f':train_and_finetune_model prov:qualifiedAssociation :{tafm_ass_uuid_writer} .',\n",
    "    f':{tafm_ass_uuid_writer} prov:agent :{model_data_code_writer} .',\n",
    "    f':{tafm_ass_uuid_writer} rdf:type prov:Association .',\n",
    "    f':{tafm_ass_uuid_writer} prov:hadRole :{code_writer_role} .',\n",
    "    \n",
    "    ########################################\n",
    "    # ONE model run - automate everything below!\n",
    "\n",
    "    # Parameter settings\n",
    "    f':{hp1_setting_run1} rdf:type mls:HyperParameterSetting .',\n",
    "    f':{hp1_setting_run1} mls:specifiedBy :hp_learning_rate .',\n",
    "    f':{hp1_setting_run1} mls:hasValue \"1.23\"^^xsd:double .',\n",
    "    f':{hp1_setting_run1} prov:wasGeneratedBy :train_and_finetune_model .',\n",
    "    # add your further parameters\n",
    "\n",
    "    # Describe your Run\n",
    "    f':{training_run1} rdf:type mls:Run .',\n",
    "    f':{training_run1} sc:isPartOf :train_and_finetune_model .',\n",
    "    f':{training_run1} mls:realizes :random_forest_algorithm .',\n",
    "    f':{training_run1} rdf:label \"Training Run 1 with...\" .',\n",
    "    f':{training_run1} mls:executes :your_implementation .', \n",
    "    f':{training_run1} mls:hasInput :training_set .',\n",
    "    f':{training_run1} mls:hasInput :validation_set .',\n",
    "    f':{training_run1} mls:hasInput :{hp1_setting_run1} .',     \n",
    "    # list all your used parameters here\n",
    "    f':{training_run1} mls:hasOutput :{model_run1} .',\n",
    "    f':{training_run1} mls:hasOutput :{eval_train_run1} .',\n",
    "    f':{training_run1} mls:hasOutput :{eval_validation_run1} .',\n",
    "\n",
    "    # Describe your Model\n",
    "    f':{model_run1} rdf:type mls:Model .',\n",
    "    f':{model_run1} prov:label \"xxx\" .',\n",
    "    f':{model_run1} prov:wasGeneratedBy :{training_run1} .',\n",
    "    f':{model_run1} mlso:trainedOn :training_set .',\n",
    "    f':{model_run1} mlso:hasAlgorithmType :random_forest_algorithm .',\n",
    "\n",
    "    # Describe your evaluations\n",
    "    # You can have multiple evaluations per model \n",
    "    f':{eval_train_run1} rdf:type mls:ModelEvaluation .',\n",
    "    f':{eval_train_run1} prov:wasGeneratedBy :{training_run1} .',\n",
    "    f':{eval_train_run1} mls:hasValue \"1.23\"^^xsd:double .',\n",
    "    f':{eval_train_run1} mls:specifiedBy :r2_score_measure .',\n",
    "    f':{eval_train_run1} prov:used :training_set .',\n",
    "\n",
    "    f':{eval_validation_run1} rdf:type mls:ModelEvaluation .',\n",
    "    f':{eval_validation_run1} prov:wasGeneratedBy :{training_run1} .',\n",
    "    f':{eval_validation_run1} mls:hasValue \"1.23\"^^xsd:double .',\n",
    "    f':{eval_validation_run1} mls:specifiedBy :r2_score_measure .',\n",
    "    f':{eval_validation_run1} prov:used :validation_set .',\n",
    "\n",
    "    # Dont forget to document any visualizations\n",
    "\n",
    "]\n",
    "engine.insert(train_model_activity, prefixes=prefixes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799b6b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrain_model_full_data(training_set, validation_set):\n",
    "    \n",
    "    # create your\n",
    "    return \"Final Trained Model\"\n",
    "\n",
    "\n",
    "start_time_tafm = now()\n",
    "# train_and_finetune_model()\n",
    "end_time_tafm = now() \n",
    "\n",
    "\n",
    "#############################################\n",
    "# Documentation 4g\n",
    "#############################################\n",
    "\n",
    "retrain_ass_uuid_writer = \"96815ee0-524c-437b-b5fa-2e15b945c993\" # Generate once\n",
    "\n",
    "final_training_activity = \":retrain_final_model\"\n",
    "final_model = \":final_model_entity\"\n",
    "\n",
    "# Document the retraining activity.\n",
    "# Hint: This activity is still part of the :modeling_phase\n",
    "\n",
    "retrain_documentation = [\n",
    "    # your documentation here    \n",
    "]\n",
    "engine.insert(retrain_documentation, prefixes=prefixes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02059271",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06583f23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a88bf71f",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46137067",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Each Activity that follows is part of the Evaluation Phase\n",
    "\n",
    "evaluation_phase_executor = [\n",
    "f':evaluation_phase rdf:type prov:Activity .',\n",
    "f':evaluation_phase rdfs:label \"Evaluation Phase\" .', \n",
    "]\n",
    "engine.insert(evaluation_phase_executor, prefixes=prefixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d80e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_code_writer = student_b\n",
    "def evaluate_on_test_data(final_model, test_set):\n",
    "\n",
    "    # Predict and evaluation on test data\n",
    "        \n",
    "    return 'Performance'\n",
    "\n",
    "start_time_eval = now()\n",
    "#evaluate_on_test_data()\n",
    "end_time_eval = now() \n",
    "\n",
    "#############################################\n",
    "# Documentation\n",
    "#############################################\n",
    "\n",
    "eval_ass_uuid = \"7f1431e9-feed-429a-92ed-c131b23cbe79\" # Generate once\n",
    "final_model = \":final_model_entity\" \n",
    "test_set = \":test_set\" \n",
    "\n",
    "eval_comment = \"\"\"\n",
    "...\n",
    "\"\"\"\n",
    "\n",
    "evaluate_activity = [\n",
    "    f':evaluate_final_model rdf:type prov:Activity .',\n",
    "    f':evaluate_final_model sc:isPartOf :evaluation_phase .',\n",
    "    f':evaluate_final_model rdfs:label \"Final Model Evaluation on Test Set\" .',\n",
    "    f':evaluate_final_model rdfs:comment \"\"\"{eval_comment}\"\"\" .',\n",
    "    f':evaluate_final_model prov:startedAtTime \"{start_time_eval}\"^^xsd:dateTime .',\n",
    "    f':evaluate_final_model prov:endedAtTime \"{end_time_eval}\"^^xsd:dateTime .',\n",
    "    f':evaluate_final_model prov:qualifiedAssociation :{eval_ass_uuid} .',\n",
    "    \n",
    "    f':{eval_ass_uuid} prov:agent :{eval_code_writer} .',\n",
    "    f':{eval_ass_uuid} rdf:type prov:Association .',\n",
    "    f':{eval_ass_uuid} prov:hadRole :{code_writer_role} .',\n",
    "\n",
    "    # Inputs\n",
    "    f':evaluate_final_model prov:used {final_model} .',\n",
    "    f':evaluate_final_model prov:used {test_set} .',\n",
    "    \n",
    "    # Reference to Data Mining Success Criteria from Phase 1\n",
    "    f':evaluate_final_model prov:used :bu_data_mining_success_criteria .',\n",
    "\n",
    "    # Document you final model performance\n",
    " \n",
    "    # Hint: you evaluate bias in this way:\n",
    "    f':bias_evaluation_result rdf:type mls:ModelEvaluation .',\n",
    "    f':bias_evaluation_result prov:wasGeneratedBy :evaluate_final_model .',\n",
    "    f':bias_evaluation_result rdfs:label \"Bias Analysis\" .',\n",
    "    f':bias_evaluation_result rdfs:comment \"...\" .',\n",
    "    \n",
    "]\n",
    "engine.insert(evaluate_activity, prefixes=prefixes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b785c94b",
   "metadata": {},
   "source": [
    "## Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013ad2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Each Activity that follows is part of the Deployment Phase\n",
    "\n",
    "deployment_phase_executor = [\n",
    "f':deployment_phase rdf:type prov:Activity .',\n",
    "f':deployment_phase rdfs:label \"Deployment Phase\" .', \n",
    "]\n",
    "engine.insert(deployment_phase_executor, prefixes=prefixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176313c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# Documentation\n",
    "#############################################\n",
    "\n",
    "comparison_and_recommendations_comment = \"\"\"\n",
    "...\n",
    "\"\"\"\n",
    "\n",
    "ethical_aspects_comment = \"\"\"\n",
    "...\n",
    "\"\"\"\n",
    "\n",
    "monitoring_plan_comment = \"\"\"\n",
    "...\n",
    "\"\"\"\n",
    "\n",
    "reproducibility_reflection_comment = \"\"\"\n",
    "...\n",
    "\"\"\"\n",
    "\n",
    "dep_ass_uuid_executor = \"72a921e0-1234-4567-89ab-cdef01234567\" # Generate once\n",
    "deployment_executor = [\n",
    "f':plan_deployment rdf:type prov:Activity .',\n",
    "f':plan_deployment sc:isPartOf :deployment_phase .', # Connect to Parent Phase\n",
    "f':plan_deployment rdfs:label \"Plan Deployment\"@en .',\n",
    "\n",
    "f':plan_deployment prov:qualifiedAssociation :{dep_ass_uuid_executor} .',\n",
    "f':{dep_ass_uuid_executor} prov:agent :{executed_by} .',\n",
    "f':{dep_ass_uuid_executor} rdf:type prov:Association .',\n",
    "f':{dep_ass_uuid_executor} prov:hadRole :{code_executor_role} .', \n",
    "]\n",
    "engine.insert(deployment_executor, prefixes=prefixes)\n",
    "\n",
    "\n",
    "deployment_data_executor = [\n",
    "#6a\n",
    "f':dep_recommendations rdf:type prov:Entity .',\n",
    "f':dep_recommendations prov:wasGeneratedBy :plan_deployment .',\n",
    "f':dep_recommendations rdfs:label \"6a Business Objectives Reflection and Deployment Recommendations\" .',\n",
    "f':dep_recommendations rdfs:comment \"\"\"{comparison_and_recommendations_comment}\"\"\" .',\n",
    "#6b\n",
    "f':dep_ethical_risks rdf:type prov:Entity .',\n",
    "f':dep_ethical_risks prov:wasGeneratedBy :plan_deployment .',\n",
    "f':dep_ethical_risks rdfs:label \"6b Ethical Aspects and Risks\" .',\n",
    "f':dep_ethical_risks rdfs:comment \"\"\"{ethical_aspects_comment}\"\"\" .',\n",
    "#6c\n",
    "f':dep_monitoring_plan rdf:type prov:Entity .',\n",
    "f':dep_monitoring_plan prov:wasGeneratedBy :plan_deployment .',\n",
    "f':dep_monitoring_plan rdfs:label \"6c Monitoring Plan\" .',\n",
    "f':dep_monitoring_plan rdfs:comment \"\"\"{monitoring_plan_comment}\"\"\" .',\n",
    "#6d\n",
    "f':dep_reproducibility_reflection rdf:type prov:Entity .',\n",
    "f':dep_reproducibility_reflection prov:wasGeneratedBy :plan_deployment .',\n",
    "f':dep_reproducibility_reflection rdfs:label \"6d Reproducibility Reflection\" .',\n",
    "f':dep_reproducibility_reflection rdfs:comment \"\"\"{reproducibility_reflection_comment}\"\"\" .',\n",
    "\n",
    "]\n",
    "engine.insert(deployment_data_executor, prefixes=prefixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e528dac9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70d410af",
   "metadata": {},
   "source": [
    "# Generate Latex Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f44e16",
   "metadata": {},
   "source": [
    "The following cells give you an example of how to automatically create a Latex Report from your provenance documentation.\n",
    "\n",
    "Feel free to use the example provided. If you use it, you should adapt and extend it with relevant sections/tables/plots/... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37046b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_iri = f\"https://starvers.ec.tuwien.ac.at/BI2025/{group_id}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d887eabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell includes cleaning functions\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "def latex_escape(text: str | None) -> str:\n",
    "    if text is None: return \"\"\n",
    "    text = str(text)\n",
    "    text = text.replace(\"\\\\\", r\"\\textbackslash{}\")\n",
    "    pairs = [\n",
    "        (\"&\", r\"\\&\"), (\"%\", r\"\\%\"), (\"$\", r\"\\$\"), (\"#\", r\"\\#\"), \n",
    "        (\"_\", r\"\\_\"), (\"{\", r\"\\{\"), (\"}\", r\"\\}\"), \n",
    "        (\"~\", r\"\\textasciitilde{}\"), (\"^\", r\"\\textasciicircum{}\")\n",
    "    ]\n",
    "    for k, v in pairs:\n",
    "        text = text.replace(k, v)\n",
    "    return text\n",
    "\n",
    "def clean_rdf(x) -> str:\n",
    "    if hasattr(x, \"toPython\"): return str(x.toPython())\n",
    "    if x is None: return \"\"\n",
    "    s = str(x).strip()\n",
    "    s = s.strip('\"').strip(\"'\")\n",
    "    s = s.strip()\n",
    "    if \"^^\" in s:\n",
    "        s = s.split(\"^^\")[0].strip('\"')\n",
    "        \n",
    "    return s\n",
    "\n",
    "def fmt_iso(ts: str) -> str:\n",
    "    if not ts: return \"\"\n",
    "    try:\n",
    "        clean_ts = ts.split(\"^^\")[0].strip('\"')\n",
    "        clean_ts = clean_ts.replace(\"Z\", \"+00:00\") if clean_ts.endswith(\"Z\") else clean_ts\n",
    "        return datetime.fromisoformat(clean_ts).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    except:\n",
    "        return latex_escape(str(ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d948da2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell includes exemplary queries for different phases\n",
    "\n",
    "\n",
    "### Author Block\n",
    "author_query = f\"\"\"\n",
    "{prefix_header}\n",
    "PREFIX iao: <http://purl.obolibrary.org/obo/>\n",
    "\n",
    "SELECT DISTINCT ?uri ?given ?family ?matr WHERE {{\n",
    "  VALUES ?uri {{ :{student_a} :{student_b} }}\n",
    "  \n",
    "  ?uri a foaf:Person .\n",
    "  ?uri foaf:givenName ?given .\n",
    "  ?uri foaf:familyName ?family .\n",
    "  ?uri iao:IAO_0000219 ?matr .\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "res_authors = engine.query(author_query)\n",
    "author_block_latex = \"\"\n",
    "\n",
    "if not res_authors.empty: # type:ignore\n",
    "    for _, row in res_authors.iterrows(): # type:ignore\n",
    "\n",
    "        uri_str = str(row['uri'])\n",
    "        given = latex_escape(clean_rdf(row['given']))\n",
    "        family = latex_escape(clean_rdf(row['family']))\n",
    "        matr = latex_escape(clean_rdf(row['matr']))\n",
    "        if student_a in uri_str:\n",
    "            responsibility = \"Student A\"\n",
    "        elif student_b in uri_str:\n",
    "            responsibility = \"Student B\"\n",
    "        else:\n",
    "            responsibility = \"Student\"\n",
    "        \n",
    "        author_block_latex += rf\"\"\"\n",
    "          \\author{{{given} {family}}}\n",
    "          \\authornote{{{responsibility}, Matr.Nr.: {matr}}}\n",
    "          \\affiliation{{\n",
    "            \\institution{{TU Wien}}\n",
    "            \\country{{Austria}}\n",
    "          }}\n",
    "          \"\"\"\n",
    "\n",
    "### Business Understanding example\n",
    "bu_query = f\"\"\"\n",
    "{prefix_header}\n",
    "\n",
    "SELECT ?ds_comment ?bo_comment WHERE {{\n",
    "  OPTIONAL {{ :bu_data_source_and_scenario rdfs:comment ?ds_comment . }}\n",
    "  OPTIONAL {{ :bu_business_objectives rdfs:comment ?bo_comment . }}\n",
    "}} LIMIT 1\n",
    "\"\"\"\n",
    "res_bu = engine.query(bu_query)\n",
    "row_bu = res_bu.iloc[0] if not res_bu.empty else {} # type:ignore\n",
    "bu_data_source = latex_escape(clean_rdf(row_bu.get(\"ds_comment\", \"\")))\n",
    "bu_objectives  = latex_escape(clean_rdf(row_bu.get(\"bo_comment\", \"\")))\n",
    "\n",
    "\n",
    "### Data Understanding examples\n",
    "# Example Dataset Description\n",
    "du_desc_query = f\"\"\"\n",
    "{prefix_header}\n",
    "SELECT ?desc WHERE {{ :raw_data sc:description ?desc . }} LIMIT 1\n",
    "\"\"\"\n",
    "res_du_desc = engine.query(du_desc_query)\n",
    "row_du_desc = res_du_desc.iloc[0] if not res_du_desc.empty else {} # type:ignore\n",
    "du_description = latex_escape(clean_rdf(row_du_desc.get(\"desc\", \"\")))\n",
    "\n",
    "# Example Feature Columns Table\n",
    "du_query = f\"\"\"\n",
    "{prefix_header}\n",
    "\n",
    "SELECT ?name (SAMPLE(?dtypeRaw) as ?dtype) (SAMPLE(?descRaw) as ?desc) WHERE {{\n",
    "  :raw_data cr:recordSet ?rs .\n",
    "  ?rs cr:field ?field .\n",
    "  ?field sc:name ?name .\n",
    "  ?field sc:description ?descRaw .\n",
    "  ?field cr:dataType ?dtypeRaw .\n",
    "}} \n",
    "GROUP BY ?name\n",
    "ORDER BY ?name\n",
    "\"\"\"\n",
    "res_du = engine.query(du_query)\n",
    "du_rows = []\n",
    "if not res_du.empty: # type:ignore\n",
    "    for _, f in res_du.iterrows(): # type:ignore\n",
    "        dtype_raw = clean_rdf(f.get(\"dtype\", \"\"))\n",
    "        if '#' in dtype_raw: dtype = dtype_raw.split('#')[-1]\n",
    "        elif '/' in dtype_raw: dtype = dtype_raw.split('/')[-1]\n",
    "        else: dtype = dtype_raw\n",
    "        \n",
    "        desc = clean_rdf(f.get(\"desc\", \"\"))\n",
    "        row_str = f\"{latex_escape(clean_rdf(f['name']))} & {latex_escape(dtype)} & {latex_escape(desc)} \\\\\\\\\"\n",
    "        du_rows.append(row_str)\n",
    "du_table_rows = \"\\n    \".join(du_rows)\n",
    "\n",
    "### Modeling example\n",
    "# Hyperparameters\n",
    "hp_query = f\"\"\"\n",
    "{prefix_header}\n",
    "\n",
    "SELECT ?hpName (SAMPLE(?hpValRaw) as ?hpVal) (MAX(?hpDescRaw) as ?hpDesc) WHERE {{\n",
    "  ?run sc:isPartOf :train_and_finetune_model .\n",
    "  ?run mls:hasInput ?setting .\n",
    "  ?setting a mls:HyperParameterSetting .\n",
    "  ?setting mls:hasValue ?hpValRaw .\n",
    "  ?setting mls:specifiedBy ?hpDef .\n",
    "  ?hpDef rdfs:label ?hpName .\n",
    "  OPTIONAL {{ ?hpDef rdfs:comment ?hpDescRaw . }}\n",
    "}} \n",
    "GROUP BY ?hpName\n",
    "ORDER BY ?hpName\n",
    "\"\"\"\n",
    "res_hp = engine.query(hp_query)\n",
    "hp_rows = []\n",
    "if not res_hp.empty: #type:ignore\n",
    "    for _, row in res_hp.iterrows(): #type:ignore\n",
    "        name = latex_escape(clean_rdf(row['hpName']))\n",
    "        val  = latex_escape(clean_rdf(row['hpVal']))\n",
    "        desc = latex_escape(clean_rdf(row.get('hpDesc', '')))\n",
    "        hp_rows.append(rf\"{name} & {desc} & {val} \\\\\")\n",
    "\n",
    "hp_table_rows = \"\\n    \".join(hp_rows)\n",
    "\n",
    "# Run Info\n",
    "run_query = f\"\"\"\n",
    "{prefix_header}\n",
    "\n",
    "SELECT ?algoLabel ?start ?end ?metricLabel ?metricVal WHERE {{\n",
    "  OPTIONAL {{ :train_and_finetune_model prov:startedAtTime ?start ; prov:endedAtTime ?end . }}\n",
    "  OPTIONAL {{\n",
    "      ?run sc:isPartOf :train_and_finetune_model .\n",
    "      ?run mls:realizes ?algo .\n",
    "      ?algo rdfs:label ?algoLabel .\n",
    "  }}\n",
    "  OPTIONAL {{\n",
    "    ?run sc:isPartOf :train_and_finetune_model .\n",
    "    ?run mls:hasOutput ?eval .\n",
    "    ?eval a mls:ModelEvaluation ; mls:hasValue ?metricVal .\n",
    "    OPTIONAL {{ ?eval mls:specifiedBy ?m . ?m rdfs:label ?metricLabel . }}\n",
    "  }}\n",
    "}} LIMIT 1\n",
    "\"\"\"\n",
    "res_run = engine.query(run_query)\n",
    "row_run = res_run.iloc[0] if not res_run.empty else {} #type:ignore\n",
    "mod_algo  = latex_escape(clean_rdf(row_run.get(\"algoLabel\", \"\")))\n",
    "mod_start = latex_escape(fmt_iso(clean_rdf(row_run.get(\"start\"))))\n",
    "mod_end   = latex_escape(fmt_iso(clean_rdf(row_run.get(\"end\"))))\n",
    "mod_m_lbl = latex_escape(clean_rdf(row_run.get(\"metricLabel\", \"\")))\n",
    "raw_val = clean_rdf(row_run.get('metricVal', ''))\n",
    "mod_m_val = f\"{float(raw_val):.4f}\" if raw_val else \"\"\n",
    "\n",
    "print(\"Data extraction done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca8fa1c",
   "metadata": {},
   "source": [
    "The following includes the Latex report itself. It fills in the query-results from the cell before. The ACM Template is already filled. \n",
    "Make sure that you update Student A and B accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9ce52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_content = rf\"\"\"\\documentclass[sigconf]{{acmart}}\n",
    "\n",
    "\\AtBeginDocument{{ \\providecommand\\BibTeX{{ Bib\\TeX }} }}\n",
    "\\setcopyright{{acmlicensed}}\n",
    "\\copyrightyear{{2025}}\n",
    "\\acmYear{{2025}}\n",
    "\\acmDOI{{XXXXXXX.XXXXXXX}}\n",
    "\n",
    "\\acmConference[BI 2025]{{Business Intelligence}}{{-}}{{-}}\n",
    "\n",
    "\\begin{{document}}\n",
    "\n",
    "\\title{{BI2025 Experiment Report - Group {group_id}}}\n",
    "%% ---Authors: Dynamically added ---\n",
    "{author_block_latex}\n",
    "\n",
    "\\begin{{abstract}}\n",
    "  This report documents the machine learning experiment for Group {group_id}, following the CRISP-DM process model.\n",
    "\\end{{abstract}}\n",
    "\n",
    "\\ccsdesc[500]{{Computing methodologies~Machine learning}}\n",
    "\\keywords{{CRISP-DM, Provenance, Knowledge Graph, Machine Learning}}\n",
    "\n",
    "\\maketitle\n",
    "\n",
    "%% --- 1. Business Understanding ---\n",
    "\\section{{Business Understanding}}\n",
    "\n",
    "\\subsection{{Data Source and Scenario}}\n",
    "{bu_data_source}\n",
    "\n",
    "\\subsection{{Business Objectives}}\n",
    "{bu_objectives}\n",
    "\n",
    "%% --- 2. Data Understanding ---\n",
    "\\section{{Data Understanding}}\n",
    "\\textbf{{Dataset Description:}} {du_description}\n",
    "\n",
    "The following features were identified in the dataset:\n",
    "\n",
    "\\begin{{table}}[h]\n",
    "  \\caption{{Raw Data Features}}\n",
    "  \\label{{tab:features}}\n",
    "  \\begin{{tabular}}{{lp{{0.2\\linewidth}}p{{0.4\\linewidth}}}}\n",
    "    \\toprule\n",
    "    \\textbf{{Feature Name}} & \\textbf{{Data Type}} & \\textbf{{Description}} \\\\\n",
    "    \\midrule\n",
    "    {du_table_rows}\n",
    "    \\bottomrule\n",
    "  \\end{{tabular}}\n",
    "\\end{{table}}\n",
    "\n",
    "%% --- 3. Data Preparation ---\n",
    "\\section{{Data Preparation}}\n",
    "\\subsection{{Data Cleaning}}\n",
    "Describe your Data preparation steps here and include respective graph data.\n",
    "\n",
    "\n",
    "%% --- 4. Modeling ---\n",
    "\\section{{Modeling}}\n",
    "\n",
    "\\subsection{{Hyperparameter Configuration}}\n",
    "The model was trained using the following hyperparameter settings:\n",
    "\n",
    "\\begin{{table}}[h]\n",
    "  \\caption{{Hyperparameter Settings}}\n",
    "  \\label{{tab:hyperparams}}\n",
    "  \\begin{{tabular}}{{lp{{0.4\\linewidth}}l}}\n",
    "    \\toprule\n",
    "    \\textbf{{Parameter}} & \\textbf{{Description}} & \\textbf{{Value}} \\\\\n",
    "    \\midrule\n",
    "    {hp_table_rows}\n",
    "    \\bottomrule\n",
    "  \\end{{tabular}}\n",
    "\\end{{table}}\n",
    "\n",
    "\\subsection{{Training Run}}\n",
    "A training run was executed with the following characteristics:\n",
    "\\begin{{itemize}}\n",
    "    \\item \\textbf{{Algorithm:}} {mod_algo}\n",
    "    \\item \\textbf{{Start Time:}} {mod_start}\n",
    "    \\item \\textbf{{End Time:}} {mod_end}\n",
    "    \\item \\textbf{{Result:}} {mod_m_lbl} = {mod_m_val}\n",
    "\\end{{itemize}}\n",
    "\n",
    "%% --- 5. Evaluation ---\n",
    "\\section{{Evaluation}}\n",
    "\n",
    "%% --- 6. Deployment ---\n",
    "\\section{{Deployment}}\n",
    "\n",
    "\\section{{Conclusion}}\n",
    "\n",
    "\\end{{document}}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c947b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell stores the Latex report to the data/report directory\n",
    "\n",
    "out_dir = os.path.join(\"data\", \"report\")\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "out_path = os.path.join(out_dir, \"experiment_report.tex\")\n",
    "\n",
    "with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(latex_content)\n",
    "\n",
    "print(f\"Report written to: {out_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BI2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
